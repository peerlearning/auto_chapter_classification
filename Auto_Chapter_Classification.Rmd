---
title: "R Notebook"
output: html_notebook
---

```{r message=FALSE, warning=FALSE}
library('tidyverse')
library('e1071')
library('SparseM')
library('tm')
library('caret')
#library('SnowballC')
#library('wordcloud')
library('jsonlite')

library(reticulate)
path_to_python <- "/usr/local/bin/python3"
use_python(path_to_python)
knitr::knit_engines$set(python = reticulate::eng_python)
py_available(initialize = TRUE)
```

## Configuration
```{r} 

# Algorithm. Choices: svm, naiveBayes, etc
algorithm = naiveBayes

# Categorical or not. Choices: TRUE or FALSE
categorical = TRUE

# Weighting function. Choices: weightTf, weightTfIdf
# Whether to normalize terms of Document Matrix. Choices: TRUE, FALSE
weightingFunction = weightTf
normalize = FALSE

# Whether to write to db
writeToDb = TRUE

```

```{r}
## Reading data from CMS
Qs <- jsonlite::fromJSON('qs_topicwise.json')
Qs <- flatten(Qs)

#Qs <- read_tsv("qs_topicwise_dump.tsv")

head(Qs)
```

### Cleaning and adding Grade, Subject, Curriculum and Chapter No 

```{r}
# Need to clean the overflow of text
Qs_clean <- Qs  %>%
  #dplyr::select(1:9) %>%                    # Keeping only the first 9 columns
  #dplyr::filter(!is.na(difficulty))  %>%    # No need to clean overflow
  dplyr::mutate(Grade = str_sub(topic_code, 5, 6), Subject = str_sub(topic_code, 1, 3), Curriculum = str_sub(topic_code, 8, 10), Ch_No = str_sub(topic_code, 12, 13))
```

### Summarizing Chapter wise # Qs in the entire JEE dataset

```{r}
repo <- Qs_clean %>% filter(Curriculum =="JEE", Subject =="MTH")

chapters_to_remove = c('Selection Test', 'Repository', 'Bridge Intervention Curriculum', 'M1.1 Scaffold test','Tally Marks')

chapters_with_no_data = c('Static Electricity')

repo <- repo %>% 
  filter(!chapter %in%  chapters_to_remove) %>%
  filter(!chapter %in%  chapters_with_no_data)

repo %>% group_by(chapter) %>% summarize(count_qs =n())

```

## Create text corpus

```{r}

repo<-repo[sample(nrow(repo)),]       ## Randomize row numbers
text_corpus <- VCorpus(VectorSource(repo$question_text)) 
lapply(text_corpus[2:4], as.character)       # Multiple docs
```

## Cleaning text 
Removing punctuations, numbers and stop words
Converting to lower case
Stemming words - learned, learning, and learns are transformed into the base form, learn
Removing additional white spaces

```{r}
# Source : [2] Removing non-UTF8 characters
text_corpus_clean <- tm_map(text_corpus, content_transformer(gsub), pattern ="[^[:alnum:]]" , replacement = " ")
text_corpus_clean <- tm_map(text_corpus_clean, content_transformer(gsub), pattern ="[\u0080-\uffff]" , replacement = " ")

## Now non-UTF characters are removed. We can do regular tasks on the clean corpus.

#text_corpus_clean <- tm_map(text_corpus_clean, removeNumbers)
text_corpus_clean <- tm_map(text_corpus_clean, content_transformer(tolower))

# Remove one letter words
text_corpus_clean <- tm_map(text_corpus_clean, content_transformer(gsub), pattern="\\b\\w{1,2}\\b", replacement = "")

## Add stopwords like left, right (frac ?)
#text_corpus_clean <- tm_map(text_corpus_clean, removeWords, c(stopwords(), "left","right"))
text_corpus_clean <- tm_map(text_corpus_clean, removePunctuation)
#text_corpus_clean <- tm_map(text_corpus_clean, stemDocument)
text_corpus_clean <- tm_map(text_corpus_clean, stripWhitespace)

lapply(text_corpus_clean[2:4], as.character)       
```

## Bag of words - Tokenization
```{r}

# TF-IDF
text_dtm <- DocumentTermMatrix(text_corpus_clean, control = list(stemming = TRUE, weighting = weightingFunction, normalize = normalize))

# Add a dictionary to DTM ?
```

## Data preparation - Creating training and test datasets
```{r}

folds <- cut(seq(1,nrow(repo)),breaks=5,labels=FALSE)
test_indices = which(folds==1, arr.ind=TRUE)

text_dtm_train <- text_dtm[-test_indices,  ]
text_dtm_test <- text_dtm[test_indices,  ]

```

## Setting Labels for prediction and checking their sample proportion (%)
```{r}
text_train_labels <- as.factor(repo[-test_indices,  ]$chapter)
text_test_labels <- as.factor(repo[test_indices,  ]$chapter) 

round(prop.table(table(text_train_labels))*100,2)
```

## Distribution of labels in test set
```{r}
round(prop.table(table(text_test_labels))*100,2)
```

## Visualizing text data - word clouds
wordcloud(text_corpus_clean, min.freq=10, random.order = FALSE)
wordcloud(text_corpus_clean[repo$chapter == "Applications of Derivatives"], max.words = 40, scale = c(3, 0.5))

## Converting DTM to a categorical data (T/F) for NB e1071 as it only takes categorical input

```{r}

## Filter features by selecting words appearing at least a specified number of times
text_freq_words <- findFreqTerms(text_dtm, 25)

# tf-idf ?
# Useful to remove words which maybe in training set but not in test set leading to an out of bounds error

text_dtm_freq_train <- text_dtm_train[ , text_freq_words]
text_dtm_freq_test <- text_dtm_test[ , text_freq_words]

convert_counts <- function(x) {
  if(categorical) {
    x <- ifelse(x > 0, "Yes", "No")
  } 
  else {
    x <- x
  }
}

# MARGIN = 1 is used for rows
text_train <- apply(text_dtm_freq_train, MARGIN = 2, convert_counts)
text_test <- apply(text_dtm_freq_test, MARGIN = 2, convert_counts)


# Laplace - This allows words that did not appear earlier to have an indisputable say in the classification process. Just because the word "ringtone" only appeared in the spam messages in the training data, it does not mean that every message with this word should be classified as spam
```

## TRAINING
```{r}
text_classifier <- algorithm(as.matrix(text_train), text_train_labels)
```

## PREDICTION
```{r}

rawResults <- predict(text_classifier,as.matrix(text_test), "raw")

results <- as.factor( colnames(rawResults)[apply(rawResults, 1, which.max)] )

true_values <- repo[test_indices, ]$chapter
test_document <- repo[test_indices, ]$question_text

## as.table((test_document,true_values, results)) ??
```

## Confusion Matrix
```{r}

conf = confusionMatrix(results, text_test_labels)
confusion_table = as.data.frame.matrix( conf$table  )
conf_stats = as.data.frame(conf$byClass)
confusion_table[nrow(confusion_table) + 1, ] <- conf_stats$Sensitivity
q_counts = repo %>% group_by(chapter) %>% summarize(count_qs =n())
confusion_table[nrow(confusion_table) + 1, ] <- t(q_counts[,2])

conf$overall
#View(conf_stats)
#View(round(confusion_table, 1))
```

```{python}

```

```{r eval=FALSE}

# Columns for category confusion dataframe
# Category, Confused labels, sentences
df = data.frame("Actual Chapter"=character(), "Accuracy"=integer(), "Wrong predicted chapters"=character(), stringsAsFactors = FALSE)
### Writing to the DB

for (label in levels(text_test_labels)) {
  groundTruth = which(text_test_labels == label)
  predTruth = which(results == label)

  falsePositives = setdiff(groundTruth, predTruth)
  falseNegatives = setdiff(predTruth, groundTruth)
  questionsFalsePos = repo[falsePositives, ]$question_text
  
  labelsFalsePos = paste(as.character(unique(results[falsePositives])), collapse = ", ")

  df[nrow(df) + 1, ] <- list(label, confusion_table[[label]][nrow(confusion_table) - 1], labelsFalsePos) 

}


```

