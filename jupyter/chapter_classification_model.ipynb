{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn module\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from sklearn import decomposition, ensemble\n",
    "\n",
    "from bs4 import BeautifulSoup, Tag    ## Cleaning HTML tags from text\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost \n",
    "import numpy as np\n",
    "#import textblob\n",
    "#import string\n",
    "\n",
    "# Keras stuff\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers\n",
    "\n",
    "import json     ## To covnert json raw data to df\n",
    "\n",
    "import pickle   ## saving the model to disk\n",
    "#from pylatexenc.latex2text import LatexNodes2Text\n",
    "pd.set_option('display.max_colwidth', -1)    ## Problem texts can be long and may not load on Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'MTH',\n",
       " 'grade': '12',\n",
       " 'curriculum': 'JEE',\n",
       " 'chapter': 'Inverse Trigonometry ',\n",
       " 'chapter_no': '18',\n",
       " 'topic': 'Introduction to Inverse Trigonometry',\n",
       " 'topic_no': '01',\n",
       " 'difficulty': '1',\n",
       " 'problem_code': 'P005930',\n",
       " 'problem_status': 'final',\n",
       " 'problem_mongo_id': '56f235d43562d97499000848',\n",
       " 'problem_type': 'Spot Test',\n",
       " 'options': ' \\\\(\\\\left[0, 2\\\\pi\\\\right]\\\\) \\\\(\\\\left[-\\\\frac{\\\\pi}2, \\\\frac{\\\\pi}2\\\\right]\\\\) \\\\(\\\\left[0, \\\\pi\\\\right]\\\\) \\\\(\\\\left[0, \\\\frac{\\\\pi}2\\\\right]\\\\)',\n",
       " 'solution': '',\n",
       " 'question_text': '\\xa0The principal domain of \\\\(\\\\tan\\u2061ùë•\\\\) is ___________\\xa0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_to_check = 'CHM'\n",
    "# Load the dataset\n",
    "labels, texts = [], []\n",
    "with open('../data/qs_topicwise.json') as json_data:\n",
    "    all_questions = json.load(json_data)\n",
    "\n",
    "all_questions[3]\n",
    "## Need to update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curriculum</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_text</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [curriculum, subject, question_text, chapter]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removing these words improves Phy clf accuracy by 2% but improves Math classifier accuracy\n",
    "words_to_remove = [\"rightarrow\", \"hence\", \"frac\", \"text\", \"sqrt\", \"times\", \"value\", \"amp\", \"statement\", \"will\", \"equal\", \"number\", \"tan\", \"now\", \"can\", \"two\", \"get\", \"true\", \"lambda\"]\n",
    "\n",
    "data_df = pd.DataFrame(columns=['curriculum', 'subject', 'question_text', 'chapter'])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which of the following statements is incorrect?</td>\n",
       "      <td>Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dry air was successively passed through a solution of \\(5\\) \\(g\\) solute in \\(90\\) \\(g\\) water and through pure water. the loss in weight of solution was \\(2.5\\) \\(g\\) and that of pure water was \\(0.05\\) \\(g.\\) molecular weight of solute in \\(g/mol\\) is \\(m.\\) find the value of \\(\\frac{m}{10}.\\)(assume that solute is non-volatile and does not dissociate or associate)</td>\n",
       "      <td>Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an aqueous solution boils at \\(374\\: k\\). what is the freezing point of the same solution?(given \\(k_f=1.86^\\circ c/m\\) and \\(k_b=0.51^\\circ c/m\\) )</td>\n",
       "      <td>Solutions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                text  \\\n",
       "0  which of the following statements is incorrect?                                                                                                                                                                                                                                                                                                                                     \n",
       "1  dry air was successively passed through a solution of \\(5\\) \\(g\\) solute in \\(90\\) \\(g\\) water and through pure water. the loss in weight of solution was \\(2.5\\) \\(g\\) and that of pure water was \\(0.05\\) \\(g.\\) molecular weight of solute in \\(g/mol\\) is \\(m.\\) find the value of \\(\\frac{m}{10}.\\)(assume that solute is non-volatile and does not dissociate or associate)   \n",
       "2  an aqueous solution boils at \\(374\\: k\\). what is the freezing point of the same solution?(given \\(k_f=1.86^\\circ c/m\\) and \\(k_b=0.51^\\circ c/m\\) )                                                                                                                                                                                                                                \n",
       "\n",
       "       label  \n",
       "0  Solutions  \n",
       "1  Solutions  \n",
       "2  Solutions  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = []\n",
    "i = 0\n",
    "for question in all_questions:\n",
    "    #topic_code = question['topic_code']  ## Not in dataset anymore, already split\n",
    "    try: \n",
    "        question_text = question['question_text'].lower()\n",
    "        #question_text = BeautifulSoup(question_text, \"html.parser\").get_text() \n",
    "        ## Beautiful Soup improves accuracy from 40% to 60% in MTH, \n",
    "        ## but reduces PHY accuracy from 60% to 20%. For CHM, \n",
    "        ## it reduces accuracy from 49% to 47% \n",
    "        question_text = \" \".join(question_text.split())\n",
    "        for word in words_to_remove:\n",
    "            question_text.replace(word, \"\")\n",
    "        #splits = topic_code.split(\"-\")\n",
    "        subject = question['subject']\n",
    "        curriculum = question['curriculum']\n",
    "        grade = question['grade']\n",
    "        curr_question = {}\n",
    "        if(\"JEE\" in curriculum and grade in [\"11\", \"12\"] and subject in subject_to_check and \"dummy\" not in question_text):\n",
    "            data_df.loc[i] = [curriculum, subject, question_text, question['chapter']]\n",
    "            i += 1\n",
    "    except:\n",
    "            pass\n",
    "\n",
    "trainDF = pd.DataFrame(columns=['text', 'label'])\n",
    "# trainDF.replace(words_to_replace, \"\")\n",
    "trainDF['text'] = data_df['question_text']\n",
    "trainDF['label'] = data_df['chapter']\n",
    "trainDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8815 2204\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.2)\n",
    "\n",
    "print(len(train_x), len(valid_x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode the target variable (for multi label classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alcohols, Ethers and Phenols', 'Aldehydes and Ketones', 'Amines',\n",
       "       'Atomic Structure ', 'Basic Concepts of Chemistry',\n",
       "       'Biomolecules, Polymers and Chemistry in Everyday life ',\n",
       "       'Carboxylic Acids and Derivatives', 'Chemical Bonding ',\n",
       "       'Chemical Equilibrium', 'Chemical Kinetics',\n",
       "       'Coordination Compounds', 'D and F Block Elements', 'Dummy',\n",
       "       'Electrochemistry', 'Environmental Chemistry',\n",
       "       'Halogen Derivatives ', 'Hydrocarbons', 'Hydrogen',\n",
       "       'Introduction to Organic Chemistry', 'Ionic Equilibrium',\n",
       "       'Metallurgy', 'Nuclear Chemistry', 'P - Block Elements - II',\n",
       "       'P block - I', 'Periodic Properties of Elements',\n",
       "       'Redox Reactions', 'Repository', 'S block elements',\n",
       "       'Selection Test', 'Solid State', 'Solutions', 'States of Matter',\n",
       "       'Surface Chemistry', 'Thermodynamics'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y = encoder.fit_transform(valid_y)\n",
    "valid_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P block - I'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform([valid_y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3480)\t1\n",
      "  (0, 4785)\t1\n",
      "  (0, 5584)\t1\n",
      "  (0, 5811)\t1\n",
      "  (0, 6397)\t1\n",
      "  (0, 8038)\t1\n",
      "  (0, 9539)\t1\n",
      "  (1, 1833)\t1\n",
      "  (1, 1884)\t1\n",
      "  (1, 2366)\t1\n",
      "  (1, 4282)\t1\n",
      "  (1, 4813)\t1\n",
      "  (1, 5584)\t1\n",
      "  (1, 6709)\t1\n",
      "  (1, 7263)\t1\n",
      "  (1, 7330)\t1\n",
      "  (1, 8443)\t1\n",
      "  (1, 8519)\t1\n",
      "  (1, 9537)\t1\n",
      "  (1, 9539)\t1\n",
      "  (2, 1359)\t1\n",
      "  (2, 1833)\t1\n",
      "  (2, 2516)\t1\n",
      "  (2, 4139)\t1\n",
      "  (2, 4183)\t1\n",
      "  :\t:\n",
      "  (8811, 7263)\t1\n",
      "  (8811, 7452)\t1\n",
      "  (8812, 2361)\t1\n",
      "  (8812, 4357)\t1\n",
      "  (8812, 4793)\t1\n",
      "  (8812, 5275)\t1\n",
      "  (8812, 5811)\t1\n",
      "  (8813, 4785)\t1\n",
      "  (8813, 5381)\t1\n",
      "  (8813, 5584)\t1\n",
      "  (8813, 5811)\t1\n",
      "  (8813, 6540)\t1\n",
      "  (8813, 6944)\t1\n",
      "  (8813, 7263)\t1\n",
      "  (8813, 9192)\t1\n",
      "  (8813, 9539)\t1\n",
      "  (8813, 10135)\t1\n",
      "  (8814, 4785)\t1\n",
      "  (8814, 5811)\t1\n",
      "  (8814, 6397)\t1\n",
      "  (8814, 7263)\t1\n",
      "  (8814, 8038)\t1\n",
      "  (8814, 8290)\t1\n",
      "  (8814, 8804)\t1\n",
      "  (8814, 9539)\t1\n"
     ]
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xtrain_count[xtrain_count != 0] = 1\n",
    "print(xtrain_count)\n",
    "\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "xvalid_count[xvalid_count != 0] = 1\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL BUILDING AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, valid_y)\n",
    "    #return metrics.f1_score(predictions, valid_y) ##?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.4941016333938294\n",
      "NB, WordLevel TF-IDF:  0.5186025408348457\n",
      "NB, N-Gram Vectors:  0.4591651542649728\n",
      "NB, CharLevel Vectors:  0.47595281306715065\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.GaussianNB(), xtrain_count.toarray(), train_y, xvalid_count.toarray())\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)\n",
    "## END MODEL BUILDING AND PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving trained model to disk, along with vectorizer & label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(xtrain_tfidf_ngram, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vect_ngram, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading pickled models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vect_ngram = pickle.load(f)\n",
    "with open('clf.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pickled models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_clf_model(text):                   ## This combined function could not be pickled !!\n",
    "    text = [text]                              ## Convert input string to a list which is an iterable needed for tf-idf\n",
    "    feat = tfidf_vect_ngram.transform(text)    ## Convert text to tfidf matrix\n",
    "    pred = clf.predict(feat)                   ## Predict label of chapter\n",
    "    cname = encoder.inverse_transform(pred)    ## Convert label to chapter name\n",
    "    return ''.join(cname)                      ## Converting array prediction to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'what is the heat capacity of plastic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thermodynamics'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing the complete model\n",
    "chapter_clf_model(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving accuracy of the classifier\n",
    "Source : https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\n",
    "* Change evaluation metric to multinomial log-loss / F1 score ?\n",
    "* Update the training set by pulling the latest dump from CMS\n",
    "* Try XGBoost classifier\n",
    "* Use Grid Search to optimize the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
