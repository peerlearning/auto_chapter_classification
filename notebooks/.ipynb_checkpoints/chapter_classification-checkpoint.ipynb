{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pritamsukumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Sklearn module\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd, xgboost, numpy, textblob, string\n",
    "\n",
    "# Keras stuff -- Commented out as not used yet\n",
    "# from keras.preprocessing import text, sequence\n",
    "# from keras import layers, models, optimizers\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "import json\n",
    "\n",
    "print(stop)\n",
    "from pylatexenc.latex2text import LatexNodes2Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    text  \\\n",
       "0     among the statements given below which one is ...   \n",
       "1                                  sin 1 left 1 2 right   \n",
       "2                      the principal domain of cos 洧논 is   \n",
       "3                          the principal domain of 洧논 is   \n",
       "4                                 1 left sin pi 2 right   \n",
       "5                         sin 1 left sin 洧논 right 洧논 if 洧논   \n",
       "6     revision exercise 5 mins the students should a...   \n",
       "7     what domain restrictions be imposed on the fun...   \n",
       "8           the principal solutions of sin x frac12 are   \n",
       "9                the general solution of sin theta 0 is   \n",
       "10                                  if cos x cos y then   \n",
       "11           if sin x 1 2 x in left 0 pi 2 right then x   \n",
       "12      the of principal solutions of cos x 1 sqrt2 are   \n",
       "13    cot 1 cos 1 cos x where alpha is some arbitrar...   \n",
       "14      if cos 1 x cos 1 y2 then 4x 2 4xy cos y 2 is to   \n",
       "15         the principal of 1 left cot 43 pi 4 right is   \n",
       "16    if f left x right 2 1 x sin 1 left 2x 1 x 2 ri...   \n",
       "17                         1 3 sin 1 left sqrt3 2 right   \n",
       "18                  the of 2 sec 1 2 cot 2 cosec 1 3 is   \n",
       "19     if cos 1 x cos 1 y cos 1 z 3 then xy yz zx is to   \n",
       "20    let f left 1 1 right b be a function defined b...   \n",
       "21                        if sin 1 3x sin 1 4x 2 then x   \n",
       "22    the of a for which ax 2 sin 1 x 2 2x 2 cos 1 x...   \n",
       "23                          if sin 1 x cos 1 x 1 x then   \n",
       "24    the trigonometric equation sin 1 x 2 sin 1 a h...   \n",
       "25    for some x 1 1 we have cos 1 x 1 x then the of...   \n",
       "26      if cos 1 x cos 1 y2 then 4x 2 4xy cos y 2 is to   \n",
       "27                     the of sin 1 frac12 cosec 1 2 is   \n",
       "28     solution of the equation 1 x 1 1 x 1 x 1 1 3x is   \n",
       "29    the of cos left pi 6 cos 1 left 1 2 right righ...   \n",
       "...                                                 ...   \n",
       "6949                                 if sin x 4 5 sec x   \n",
       "6950  for an angle a which does not exceed 90 circ c...   \n",
       "6951  in triangle abc right angled at b if a 3 find ...   \n",
       "6952  in delta pqr right angled at q qr 8 cm and the...   \n",
       "6953                       sec 68 circ is equivalent to   \n",
       "6954  which of the following values are not defined ...   \n",
       "6955                            2 tan30 circ 1 230 circ   \n",
       "6956         which of the following identities is false   \n",
       "6957           tan1 circ tan2 circ tan3 circ tan89 circ   \n",
       "6958  if the angle of elevation of a bird sitting on...   \n",
       "6959  the angles of elevation from points at distanc...   \n",
       "6960  the angle of elevation of the top of a flag po...   \n",
       "6961      if b 15 then of 4 sin 2b cos 4b sin 6b equals   \n",
       "6962     which out of the following identities is false   \n",
       "6963    if x sin 45 circ cos 45 circ sin 30 circ then x   \n",
       "6964                   the slope of the line 3x 7 5y is   \n",
       "6965  find the angle which the line joining the poin...   \n",
       "6966  which of the following lines has a higher abso...   \n",
       "6967  is the given equation 2x 3y 6 0 going upwards ...   \n",
       "6968                                       d dx cosec x   \n",
       "6969                       d dx left 3e x 4 cos x right   \n",
       "6970  in the figure identify the sign of the slope o...   \n",
       "6971  the displacement of a particle varies with tim...   \n",
       "6972  the displacement of a particle varies with tim...   \n",
       "6973  the displacement of a particle varies with tim...   \n",
       "6974  for which of the following functions the insta...   \n",
       "6975  differentiation of sin x x using the product r...   \n",
       "6976  differentiation of x ln x using the product ru...   \n",
       "6977                               d dx left 3x x right   \n",
       "6978                            d dx left 2 x e x right   \n",
       "\n",
       "                           label  \n",
       "0          Inverse Trigonometry   \n",
       "1          Inverse Trigonometry   \n",
       "2          Inverse Trigonometry   \n",
       "3          Inverse Trigonometry   \n",
       "4          Inverse Trigonometry   \n",
       "5          Inverse Trigonometry   \n",
       "6          Inverse Trigonometry   \n",
       "7          Inverse Trigonometry   \n",
       "8          Inverse Trigonometry   \n",
       "9          Inverse Trigonometry   \n",
       "10         Inverse Trigonometry   \n",
       "11         Inverse Trigonometry   \n",
       "12         Inverse Trigonometry   \n",
       "13         Inverse Trigonometry   \n",
       "14         Inverse Trigonometry   \n",
       "15         Inverse Trigonometry   \n",
       "16         Inverse Trigonometry   \n",
       "17         Inverse Trigonometry   \n",
       "18         Inverse Trigonometry   \n",
       "19         Inverse Trigonometry   \n",
       "20         Inverse Trigonometry   \n",
       "21         Inverse Trigonometry   \n",
       "22         Inverse Trigonometry   \n",
       "23         Inverse Trigonometry   \n",
       "24         Inverse Trigonometry   \n",
       "25         Inverse Trigonometry   \n",
       "26         Inverse Trigonometry   \n",
       "27         Inverse Trigonometry   \n",
       "28         Inverse Trigonometry   \n",
       "29         Inverse Trigonometry   \n",
       "...                          ...  \n",
       "6949   Trigonometry - Foundation  \n",
       "6950   Trigonometry - Foundation  \n",
       "6951   Trigonometry - Foundation  \n",
       "6952   Trigonometry - Foundation  \n",
       "6953   Trigonometry - Foundation  \n",
       "6954   Trigonometry - Foundation  \n",
       "6955   Trigonometry - Foundation  \n",
       "6956   Trigonometry - Foundation  \n",
       "6957   Trigonometry - Foundation  \n",
       "6958   Trigonometry - Foundation  \n",
       "6959   Trigonometry - Foundation  \n",
       "6960   Trigonometry - Foundation  \n",
       "6961   Trigonometry - Foundation  \n",
       "6962   Trigonometry - Foundation  \n",
       "6963   Trigonometry - Foundation  \n",
       "6964  Calculus - Differentiation  \n",
       "6965  Calculus - Differentiation  \n",
       "6966  Calculus - Differentiation  \n",
       "6967  Calculus - Differentiation  \n",
       "6968  Calculus - Differentiation  \n",
       "6969  Calculus - Differentiation  \n",
       "6970  Calculus - Differentiation  \n",
       "6971  Calculus - Differentiation  \n",
       "6972  Calculus - Differentiation  \n",
       "6973  Calculus - Differentiation  \n",
       "6974  Calculus - Differentiation  \n",
       "6975  Calculus - Differentiation  \n",
       "6976  Calculus - Differentiation  \n",
       "6977  Calculus - Differentiation  \n",
       "6978  Calculus - Differentiation  \n",
       "\n",
       "[6614 rows x 2 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "subject_to_check = 'MTH'\n",
    "# Load the dataset\n",
    "labels, texts = [], []\n",
    "with open('../data/qs_topicwise.json') as json_data:\n",
    "    all_questions = json.load(json_data)\n",
    "\n",
    "words_to_remove = [\"rightarrow\", \"hence\", \"frac\", \"text\", \"sqrt\", \"times\", \"value\", \"amp\", \"statement\", \"will\", \"equal\", \"number\", \"tan\", \"now\", \"can\", \"two\", \"get\", \"true\", \"lambda\"]\n",
    "# words_to_remove += stop\n",
    "\n",
    "chapters_to_remove = ['Selection Test', 'Repository', 'Bridge Intervention Curriculum', 'M1.1 Scaffold test','Tally Marks'\n",
    ", 'Principle of Mathematical Induction']\n",
    "\n",
    "data_df = pd.DataFrame(columns=['curriculum', 'subject', 'question_text', 'chapter'])\n",
    "questions = []\n",
    "i = 0\n",
    "\n",
    "# Regex pattern for keeping only alphabets and numbers\n",
    "pattern = re.compile('[\\W_]+')\n",
    "nonutf8pattern = re.compile('[\\u0080-\\uffff]')\n",
    "\n",
    "for question in all_questions:\n",
    "    try: # So that python doesn't crash on individual question exceptions\n",
    "        question_text = question['question_text'].lower()\n",
    "        \n",
    "        question_text = pattern.sub(\" \", question_text)\n",
    "        question_text = nonutf8pattern.sub(\" \", question_text)\n",
    "\n",
    "\n",
    "        # Remove extra whitespaces\n",
    "        question_text = \" \".join([word for word in question_text.split() if word not in words_to_remove])\n",
    "        question_text = \" \".join(question_text.split())\n",
    "\n",
    "        \n",
    "        # Keep only alphanumeric characters\n",
    "        subject = question['subject']\n",
    "        curriculum = question['curriculum']\n",
    "        grade = question['grade']\n",
    "        if(\"JEE\" in curriculum and subject in subject_to_check):\n",
    "            data_df.loc[i] = [curriculum, subject, question_text, question['chapter']]\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "trainDF = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "# trainDF.replace(words_to_replace, \"\")\n",
    "trainDF['text'] = data_df['question_text']\n",
    "trainDF['label'] = data_df['chapter']\n",
    "\n",
    "for chapter in chapters_to_remove:\n",
    "    trainDF = trainDF[trainDF['label'] != chapter]\n",
    "display(trainDF.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     among the statements given below which one is ...\n",
      "1                                  sin 1 left 1 2 right\n",
      "2                      the principal domain of cos 洧논 is\n",
      "3                          the principal domain of 洧논 is\n",
      "4                                 1 left sin pi 2 right\n",
      "5                         sin 1 left sin 洧논 right 洧논 if 洧논\n",
      "6     revision exercise 5 mins the students should a...\n",
      "7     what domain restrictions be imposed on the fun...\n",
      "8           the principal solutions of sin x frac12 are\n",
      "9                the general solution of sin theta 0 is\n",
      "10                                  if cos x cos y then\n",
      "11           if sin x 1 2 x in left 0 pi 2 right then x\n",
      "12      the of principal solutions of cos x 1 sqrt2 are\n",
      "13    cot 1 cos 1 cos x where alpha is some arbitrar...\n",
      "14      if cos 1 x cos 1 y2 then 4x 2 4xy cos y 2 is to\n",
      "15         the principal of 1 left cot 43 pi 4 right is\n",
      "16    if f left x right 2 1 x sin 1 left 2x 1 x 2 ri...\n",
      "17                         1 3 sin 1 left sqrt3 2 right\n",
      "18                  the of 2 sec 1 2 cot 2 cosec 1 3 is\n",
      "19     if cos 1 x cos 1 y cos 1 z 3 then xy yz zx is to\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "len(trainDF)\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(trainDF['text'][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5291 1323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3104    if log left x y 3 right 12 log x 12 log y then...\n",
       "3084                    int left 1 x 1 x 2 x e x right dx\n",
       "5759                how many 4 digit numbers are possible\n",
       "1827    let m be a 2 2 symmetric matrix with integer e...\n",
       "5888    the of ways of dividing 9 players into teams o...\n",
       "4094    180 circ is equivalent to which of the followi...\n",
       "4434    given 洧녩 gt 洧녪 then 洧녩 2 gt 洧녪 2 is for i 洧녩 gt 0 洧녪...\n",
       "3179    p n denotes the of natural less than n which a...\n",
       "6159    the expression left 2x 2 1 2x 2 1 right 6 left...\n",
       "1268    if the v vectors overrightarrow a overrightarr...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and testing folds\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.2, random_state=42)\n",
    "print(str(len(train_x)) + \" \" + str(len(valid_x)))\n",
    "\n",
    "# Label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- FEATURE ENGINEERING -----\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', binary=True, max_features=3513)\n",
    "X = count_vect.fit_transform(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the principal domain of cos 洧논 is'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = count_vect.vocabulary_\n",
    "# y = list(x.keys() )\n",
    "# print(sorted(y))\n",
    "\n",
    "trainDF['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cotb',\n",
       " 'coterminous',\n",
       " 'cotrapositive',\n",
       " 'count',\n",
       " 'counters',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'covering',\n",
       " 'covert',\n",
       " 'cpb',\n",
       " 'cream',\n",
       " 'creams',\n",
       " 'crew',\n",
       " 'cs',\n",
       " 'cu',\n",
       " 'cubical',\n",
       " 'currency',\n",
       " 'cutting',\n",
       " 'cv',\n",
       " 'dac',\n",
       " 'daily',\n",
       " 'dairy',\n",
       " 'dalmatian',\n",
       " 'dance',\n",
       " 'dash',\n",
       " 'dat',\n",
       " 'dataclass',\n",
       " 'dataheight',\n",
       " 'daughters',\n",
       " 'daynumber',\n",
       " 'dayoption',\n",
       " 'ddot',\n",
       " 'deal',\n",
       " 'dealt',\n",
       " 'debate',\n",
       " 'december',\n",
       " 'decide',\n",
       " 'deck',\n",
       " 'decompose',\n",
       " 'decrease',\n",
       " 'defining',\n",
       " 'deleted',\n",
       " 'deliveries',\n",
       " 'demand',\n",
       " 'denomination',\n",
       " 'dentoes',\n",
       " 'depicts',\n",
       " 'deposit',\n",
       " 'deposited',\n",
       " 'deposits',\n",
       " 'depth',\n",
       " 'derivation',\n",
       " 'derive',\n",
       " 'descending',\n",
       " 'description',\n",
       " 'design',\n",
       " 'detector',\n",
       " 'dg',\n",
       " 'dicitionary',\n",
       " 'differences',\n",
       " 'differentiablenot',\n",
       " 'differentials',\n",
       " 'differentiating',\n",
       " 'differentiations',\n",
       " 'diffrential',\n",
       " 'directionwe',\n",
       " 'directly',\n",
       " 'directories',\n",
       " 'discarded',\n",
       " 'discovered',\n",
       " 'discrete',\n",
       " 'disease',\n",
       " 'dishonest',\n",
       " 'disjointregion',\n",
       " 'distibuted',\n",
       " 'distributionclasses',\n",
       " 'doberman',\n",
       " 'doctor',\n",
       " 'doesn',\n",
       " 'doubles',\n",
       " 'dr',\n",
       " 'draws',\n",
       " 'driving',\n",
       " 'dropped',\n",
       " 'du',\n",
       " 'ducks',\n",
       " 'dv',\n",
       " 'e16',\n",
       " 'ea',\n",
       " 'earners',\n",
       " 'earth',\n",
       " 'eastwards',\n",
       " 'eb',\n",
       " 'eccentriciyt',\n",
       " 'economical',\n",
       " 'edge',\n",
       " 'edx',\n",
       " 'ef',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'elimination',\n",
       " 'emanating',\n",
       " 'emitted',\n",
       " 'employees',\n",
       " 'enclose',\n",
       " 'encounter',\n",
       " 'endanoele',\n",
       " 'endeanoel',\n",
       " 'endlessly',\n",
       " 'engineering',\n",
       " 'enlarge',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'entity',\n",
       " 'epsilon',\n",
       " 'equaliv',\n",
       " 'equallydistribute',\n",
       " 'equationi',\n",
       " 'equivalently',\n",
       " 'erases',\n",
       " 'erasing',\n",
       " 'escape',\n",
       " 'eta',\n",
       " 'etc',\n",
       " 'evaluating',\n",
       " 'evening',\n",
       " 'evenstatement',\n",
       " 'eventsiii',\n",
       " 'eventswhich',\n",
       " 'everyone',\n",
       " 'exam',\n",
       " 'examine',\n",
       " 'exams',\n",
       " 'exchanged',\n",
       " 'excluded',\n",
       " 'exercise',\n",
       " 'exp',\n",
       " 'expanding',\n",
       " 'expands',\n",
       " 'expanses',\n",
       " 'expansions',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'experiments',\n",
       " 'explain',\n",
       " 'expresion',\n",
       " 'exradius',\n",
       " 'extended',\n",
       " 'extends',\n",
       " 'exterior',\n",
       " 'external',\n",
       " 'extrema',\n",
       " 'ey',\n",
       " 'eyes',\n",
       " 'faced',\n",
       " 'factional',\n",
       " 'factorial',\n",
       " 'factoring',\n",
       " 'factorisation',\n",
       " 'factorized',\n",
       " 'fahrenheit',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'falling',\n",
       " 'fan',\n",
       " 'farther',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'fatal',\n",
       " 'fc',\n",
       " 'feeling',\n",
       " 'female',\n",
       " 'fencing',\n",
       " 'file',\n",
       " 'fin',\n",
       " 'finger',\n",
       " 'fingers',\n",
       " 'finitely',\n",
       " 'fires',\n",
       " 'firm',\n",
       " 'firms',\n",
       " 'fish',\n",
       " 'flag',\n",
       " 'flaws',\n",
       " 'flow',\n",
       " 'flower',\n",
       " 'flows',\n",
       " 'fnd',\n",
       " 'fo',\n",
       " 'followed',\n",
       " 'followinglist',\n",
       " 'forecasts',\n",
       " 'formation',\n",
       " 'formulated',\n",
       " 'forward',\n",
       " 'frac12p',\n",
       " 'frac15',\n",
       " 'frac18',\n",
       " 'frac1e',\n",
       " 'frac1k',\n",
       " 'frac1m',\n",
       " 'frac1n',\n",
       " 'frac1t',\n",
       " 'frac1y',\n",
       " 'frac1z',\n",
       " 'frac23a',\n",
       " 'frac32x',\n",
       " 'frac34',\n",
       " 'frac35',\n",
       " 'frac4',\n",
       " 'frac43ps',\n",
       " 'frac45',\n",
       " 'frac5',\n",
       " 'frac72',\n",
       " 'freely',\n",
       " 'freight',\n",
       " 'front',\n",
       " 'fuel',\n",
       " 'funciotn',\n",
       " 'functioniiiiiiv',\n",
       " 'functionquadrant',\n",
       " 'fund',\n",
       " 'gab',\n",
       " 'gap',\n",
       " 'garden',\n",
       " 'gave',\n",
       " 'gcd',\n",
       " 'gd',\n",
       " 'ge26',\n",
       " 'ge2y',\n",
       " 'ge4x',\n",
       " 'ge8',\n",
       " 'geese',\n",
       " 'geometrically',\n",
       " 'geometry',\n",
       " 'geq1',\n",
       " 'geq2',\n",
       " 'geq2x',\n",
       " 'geq3',\n",
       " 'germany',\n",
       " 'ghar',\n",
       " 'gifts',\n",
       " 'goa',\n",
       " 'governed',\n",
       " 'graduate',\n",
       " 'grand',\n",
       " 'graphical',\n",
       " 'grass',\n",
       " 'gravitational',\n",
       " 'gravity',\n",
       " 'grows',\n",
       " 'guessing',\n",
       " 'gx',\n",
       " 'hae',\n",
       " 'hall',\n",
       " 'halt',\n",
       " 'halting',\n",
       " 'halves',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'haryana',\n",
       " 'hasonly',\n",
       " 'hastwo',\n",
       " 'heating',\n",
       " 'heights',\n",
       " 'heightweightmean',\n",
       " 'hens',\n",
       " 'hh',\n",
       " 'hindustan',\n",
       " 'hline',\n",
       " 'home',\n",
       " 'hot',\n",
       " 'houses',\n",
       " 'however',\n",
       " 'human',\n",
       " 'hunter',\n",
       " 'husband',\n",
       " 'husky',\n",
       " 'hx',\n",
       " 'hydrochloric',\n",
       " 'hypotenuse',\n",
       " 'h洧논',\n",
       " 'i3',\n",
       " 'ibt',\n",
       " 'idempotent',\n",
       " 'ignoring',\n",
       " 'iiabscissa',\n",
       " 'iiconsider',\n",
       " 'iifor',\n",
       " 'iiplane',\n",
       " 'iiroots',\n",
       " 'iistraight',\n",
       " 'illness',\n",
       " 'illuminated',\n",
       " 'immediately',\n",
       " 'implicity',\n",
       " 'imposed',\n",
       " 'inclination',\n",
       " 'include',\n",
       " 'incomplete',\n",
       " 'increment',\n",
       " 'independently',\n",
       " 'indianoil',\n",
       " 'indians',\n",
       " 'indigo',\n",
       " 'indirect',\n",
       " 'individually',\n",
       " 'industry',\n",
       " 'inersection',\n",
       " 'inex',\n",
       " 'infer',\n",
       " 'inner',\n",
       " 'input',\n",
       " 'inscribe',\n",
       " 'installment',\n",
       " 'instances',\n",
       " 'int2sec',\n",
       " 'int3',\n",
       " 'int4',\n",
       " 'int5',\n",
       " 'int7e',\n",
       " 'integera',\n",
       " 'integeriv',\n",
       " 'integrate',\n",
       " 'intelligent',\n",
       " 'interesect',\n",
       " 'interesting',\n",
       " 'international',\n",
       " 'intervention',\n",
       " 'intoidentify',\n",
       " 'intuition',\n",
       " 'inviting',\n",
       " 'involving',\n",
       " 'ion',\n",
       " 'is18the',\n",
       " 'is4if',\n",
       " 'iscontinuous',\n",
       " 'isdifferentiable',\n",
       " 'isf',\n",
       " 'isneither',\n",
       " 'ithe',\n",
       " 'iw',\n",
       " 'ixx',\n",
       " 'j1',\n",
       " 'jack',\n",
       " 'january',\n",
       " 'jaya',\n",
       " 'jc',\n",
       " 'jee',\n",
       " 'jerry',\n",
       " 'jill',\n",
       " 'job',\n",
       " 'joined',\n",
       " 'journey',\n",
       " 'juice',\n",
       " 'july',\n",
       " 'junction',\n",
       " 'june',\n",
       " 'juniors',\n",
       " 'k2',\n",
       " 'kf',\n",
       " 'kg',\n",
       " 'kink',\n",
       " 'knows',\n",
       " 'kohli',\n",
       " 'konkan',\n",
       " 'kota',\n",
       " 'kq',\n",
       " 'kr',\n",
       " 'ks',\n",
       " 'kunal',\n",
       " 'kxy',\n",
       " 'kz',\n",
       " 'k洧녽',\n",
       " 'labeled',\n",
       " 'labrador',\n",
       " 'laid',\n",
       " 'lamp',\n",
       " 'lamps',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'laps',\n",
       " 'latera',\n",
       " 'latusrecta',\n",
       " 'lawii',\n",
       " 'lawiii',\n",
       " 'lawiv',\n",
       " 'layers',\n",
       " 'le11',\n",
       " 'le15',\n",
       " 'le18',\n",
       " 'le36',\n",
       " 'le3x',\n",
       " 'le4x',\n",
       " 'le4y',\n",
       " 'le7',\n",
       " 'leq8',\n",
       " 'lettered',\n",
       " 'li9ne',\n",
       " 'library',\n",
       " 'licence',\n",
       " 'licences',\n",
       " 'liked',\n",
       " 'lineif',\n",
       " 'listed',\n",
       " 'literal',\n",
       " 'liters',\n",
       " 'litres',\n",
       " 'lives',\n",
       " 'll',\n",
       " 'ln25',\n",
       " 'ln3',\n",
       " 'ln3x',\n",
       " 'ln5x',\n",
       " 'lnx',\n",
       " 'loan',\n",
       " 'locality',\n",
       " 'loci',\n",
       " 'log6',\n",
       " 'logics',\n",
       " 'logx',\n",
       " 'log洧녩',\n",
       " 'log洧녪',\n",
       " 'log洧녫',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lowest',\n",
       " 'loyal',\n",
       " 'm0',\n",
       " 'madrid',\n",
       " 'magnitudes',\n",
       " 'malayalam',\n",
       " 'male',\n",
       " 'males',\n",
       " 'managed',\n",
       " 'manchester',\n",
       " 'mango',\n",
       " 'manned',\n",
       " 'manners',\n",
       " 'mantissa',\n",
       " 'map',\n",
       " 'mapping',\n",
       " 'marathi',\n",
       " 'march',\n",
       " 'market',\n",
       " 'marksnumber',\n",
       " 'mass',\n",
       " 'master',\n",
       " 'material',\n",
       " 'mathematicians',\n",
       " 'maximums',\n",
       " 'maybe',\n",
       " 'mc',\n",
       " 'me',\n",
       " 'mechanical',\n",
       " 'medicine',\n",
       " 'mediterranean',\n",
       " 'melts',\n",
       " 'menu',\n",
       " 'met',\n",
       " 'metal',\n",
       " 'methodheight',\n",
       " 'mf',\n",
       " 'midterm',\n",
       " 'miles',\n",
       " 'millioniv',\n",
       " 'minimal',\n",
       " 'minimizes',\n",
       " 'minimums',\n",
       " 'ministers',\n",
       " 'mins',\n",
       " 'mistress',\n",
       " 'moderately',\n",
       " 'moduleafter',\n",
       " 'moivre',\n",
       " 'momentarily',\n",
       " 'monthiii',\n",
       " 'moreover',\n",
       " 'motor',\n",
       " 'mouse',\n",
       " 'mouth',\n",
       " 'mq',\n",
       " 'mqr',\n",
       " 'mrn',\n",
       " 'mrs',\n",
       " 'mrt',\n",
       " 'mt',\n",
       " 'mth',\n",
       " 'mu3',\n",
       " 'multiply',\n",
       " 'mystery',\n",
       " 'n128',\n",
       " 'n2',\n",
       " 'n8',\n",
       " 'nagpur',\n",
       " 'named',\n",
       " 'napier',\n",
       " 'narrow',\n",
       " 'navimumbai',\n",
       " 'ne4',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'nearer',\n",
       " 'necklaces',\n",
       " 'neglecting',\n",
       " 'neighbour',\n",
       " 'neighbours',\n",
       " 'neq0',\n",
       " 'newspapers',\n",
       " 'ni',\n",
       " 'night',\n",
       " 'nilpotent',\n",
       " 'ninth',\n",
       " 'nj',\n",
       " 'nk',\n",
       " 'nm',\n",
       " 'nn',\n",
       " 'northwards',\n",
       " 'notebook',\n",
       " 'notes',\n",
       " 'november',\n",
       " 'nq',\n",
       " 'numberii',\n",
       " 'numberzeroan',\n",
       " 'nw',\n",
       " 'nxdx',\n",
       " 'nz',\n",
       " 'oabcd',\n",
       " 'oac',\n",
       " 'oacb',\n",
       " 'obd',\n",
       " 'objectsstatement',\n",
       " 'observe',\n",
       " 'observes',\n",
       " 'obtaining',\n",
       " 'occupied',\n",
       " 'occuring',\n",
       " 'octant',\n",
       " 'october',\n",
       " 'odc',\n",
       " 'oe',\n",
       " 'offer',\n",
       " 'often',\n",
       " 'oi',\n",
       " 'omitted',\n",
       " 'omn',\n",
       " 'oncircleif',\n",
       " 'onhyperbola',\n",
       " 'operating',\n",
       " 'opqrs',\n",
       " 'oqd',\n",
       " 'orange',\n",
       " 'orders',\n",
       " 'originating',\n",
       " 'orthonormal',\n",
       " 'oscillation',\n",
       " 'ot',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'outer',\n",
       " 'output',\n",
       " 'owned',\n",
       " 'owner',\n",
       " 'p2',\n",
       " 'p3',\n",
       " 'pac',\n",
       " 'pairwise',\n",
       " 'paise',\n",
       " 'pap',\n",
       " 'papers',\n",
       " 'parablas',\n",
       " 'parabolaif',\n",
       " 'parabolic',\n",
       " 'parallelepiped',\n",
       " 'parallelogrm',\n",
       " 'parbola',\n",
       " 'parcel',\n",
       " 'parcels',\n",
       " 'park',\n",
       " 'participant',\n",
       " 'participants',\n",
       " 'participated',\n",
       " 'partly',\n",
       " 'partner',\n",
       " 'pascal',\n",
       " 'passenger',\n",
       " 'passengers',\n",
       " 'passess',\n",
       " 'passport',\n",
       " 'paths',\n",
       " 'patients',\n",
       " 'pattern',\n",
       " 'pay',\n",
       " 'pays',\n",
       " '洧랝洧논',\n",
       " '洧랝洧녽'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.stop_words_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.4305157593123209\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.GaussianNB(), xtrain_count.todense(), train_y, xvalid_count.todense())\n",
    "print(\"NB, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
