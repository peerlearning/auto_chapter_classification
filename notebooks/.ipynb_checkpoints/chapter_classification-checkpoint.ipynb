{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pritamsukumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Sklearn module\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd, xgboost, numpy, textblob, string\n",
    "\n",
    "# Keras stuff -- Commented out as not used yet\n",
    "# from keras.preprocessing import text, sequence\n",
    "# from keras import layers, models, optimizers\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "import json\n",
    "\n",
    "from pylatexenc.latex2text import LatexNodes2Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_to_check = 'MTH'\n",
    "# Load the dataset\n",
    "labels, texts = [], []\n",
    "with open('../data/qs_topicwise.json') as json_data:\n",
    "    all_questions = json.load(json_data)\n",
    "\n",
    "words_to_remove = [\"rightarrow\", \"hence\", \"frac\", \"text\", \"sqrt\", \"times\", \"value\", \"amp\", \"statement\", \"will\", \"equal\", \"number\", \"tan\", \"now\", \"can\", \"two\", \"get\", \"true\", \"lambda\"]\n",
    "# words_to_remove += stop\n",
    "\n",
    "data_df = pd.DataFrame(columns=['curriculum', 'subject', 'question_text', 'chapter'])\n",
    "questions = []\n",
    "i = 0\n",
    "\n",
    "# Regex pattern for keeping only alphabets and numbers\n",
    "pattern = re.compile('[^[:alnum:]]+')\n",
    "nonutf8pattern = re.compile('[\\u0080-\\uffff]')\n",
    "questions = all_questions[1:2]\n",
    "\n",
    "for question in all_questions:\n",
    "    try: # So that python doesn't crash on individual question exceptions\n",
    "        question_text = question['question_text'].lower()\n",
    "        \n",
    "        question_text = pattern.sub(\" \", question_text)\n",
    "        question_text = nonutf8pattern.sub(\" \", question_text)\n",
    "\n",
    "\n",
    "        # Remove extra whitespaces\n",
    "        question_text = \" \".join([word for word in question_text.split() if word not in words_to_remove])\n",
    "        question_text = \" \".join(question_text.split())\n",
    "\n",
    "        \n",
    "        # Keep only alphanumeric characters\n",
    "        \n",
    "        subject = question['subject']\n",
    "        curriculum = question['curriculum']\n",
    "        grade = question['grade']\n",
    "        curr_question = {}\n",
    "        if(\"JEE\" in curriculum and subject in subject_to_check):\n",
    "            data_df.loc[i] = [curriculum, subject, question_text, question['chapter']]\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "trainDF = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "# trainDF.replace(words_to_replace, \"\")\n",
    "trainDF['text'] = data_df['question_text']\n",
    "trainDF['label'] = data_df['chapter']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5583 1396\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing folds\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.2)\n",
    "\n",
    "print(len(train_x), len(valid_x) )\n",
    "\n",
    "# Label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- FEATURE ENGINEERING -----\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', binary=True, max_features=3500)\n",
    "X = count_vect.fit_transform(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '00', '000', '000001', '0001', '0002', '002', '01', '02', '025', '07', '0f', '1', '10', '100', '1000', '10000', '100000', '1000c_', '1001', '100d', '100x', '101', '1011', '1011121314frequency', '1012', '102', '1024', '103', '104', '105', '106', '107', '108', '1080', '109', '10ax', '10b', '10cx', '10i', '10th', '10x', '10y', '11', '110', '11040', '111', '112', '115', '117', '119', '11b', '11d', '11i', '11if', '11t', '11x', '11y', '12', '120', '120g', '121', '1234', '125', '126', '127', '128', '12a', '12i', '12m', '12t', '12x', '12y', '12z', '13', '130', '130p_2', '135', '136', '1361', '137', '139', '13x', '14', '140', '1400', '1410', '1413', '144', '145', '1450', '1457', '149', '14a', '14x', '14y', '15', '150', '150x', '15101051', '152', '153', '1530', '155', '156', '157', '15b', '15i', '15th', '15x', '16', '160', '162', '164', '169', '16ax', '16q', '16x', '16y', '16z_2z_3z_4', '17', '1720', '175', '178', '17f', '17th', '17x', '18', '180', '1800', '183', '185', '18e', '18i', '18x', '18xy', '18y', '18z', '19', '1992', '1_', '1_0', '1_0f', '1a', '1b', '1c', '1c_2', '1column', '1k', '1st', '1x', '1z', '2', '20', '200', '2000', '2003', '2009', '201', '2010', '2011b', '2012', '2012b', '2013', '2013f', '2014', '2015', '2016', '2017', '2020', '2023', '207', '20c', '20i', '20let', '20th', '20x', '20y', '21', '210', '2100', '212', '215', '216', '2187', '21x', '21y', '22', '220', '2228', '225', '22j', '22t', '22x', '23', '230', '23the', '24', '240', '240g', '243', '243x', '2475', '24i', '24x', '24xy', '24y', '25', '250', '2500', '252', '2520', '253', '255', '256', '25a', '25px', '25x', '25y', '26', '260', '261', '26i', '26x', '27', '270', '2700', '2717y', '2727', '27i', '27x', '27z_2z_3', '28', '288', '28x', '29', '29x', '2_', '2_0', '2_0f', '2_1', '2_2', '2_i', '2a', '2a_1', '2a_2', '2a_8', '2a_9', '2ab', '2ac', '2acy', '2ar', '2as', '2at', '2at_1', '2at_2', '2ax', '2ay', '2b', '2b_1', '2bt', '2bx', '2by', '2c', '2c_0', '2c_1', '2c_3', '2c_r', '2column', '2cosx', '2cx', '2cxy', '2d', '2dt', '2dx', '2dy', '2e', '2ex', '2f', '2f_1f_2', '2f_2', '2figure', '2fy', '2g', '2g_1g_2', '2given', '2gx', '2h', '2hxy', '2i', '2i3', '2if', '2iy', '2j', '2k', '2kx', '2let', '2logx', '2logxdx', '2m', '2mx', '2n', '2nd', '2p', '2p_1', '2p_2', '2p_6', '2px', '2q', '2qy', '2r', '2region', '2s', '2sin', '2sin2x', '2t', '2tf', '2the', '2u', '2w', '2x', '2x_1', '2x_2', '2x_3', '2x_n', '2xi', '2xlogxdx', '2xn', '2xy', '2y', '2yi', '2yz', '2z', '2z_2', '2z_3', '2ğ‘', '2ğ‘“ğ‘¦', '2ğ‘”ğ‘¥', '2ğ‘–', '2ğ‘¥', '2ğ‘¦', '2ğœ‹', '3', '30', '300', '3000', '30000', '301', '3069', '30th', '30x', '30y', '31', '32', '321', '32x', '32y', '33', '34', '35', '351', '35m', '36', '361', '365', '368', '36x', '37', '3789108', '379', '38', '380', '39', '392', '3_', '3_0', '3_0f', '3_0x', '3_1', '3_1x', '3_2', '3_2f', '3_i', '3a', '3ab', '3abc', '3abx', '3ac', '3ax', '3b', '3by', '3c', '3c_1x', '3c_2', '3c_4', '3c_r', '3cy', '3d', '3dx', '3e', '3f', '3figure', '3g', '3i', '3i2y', '3ix', '3j', '3k', '3m', '3mn', '3n', '3p', '3p_2', '3p_3', '3q', '3r', '3rd', '3s_n', '3t', '3u', '3x', '3x_2', '3x_n', '3xy', '3y', '3z', '3z_1', '3z_2', '3ğ·', '3ğ‘“', '3ğ‘–', '3ğ‘š', '3ğ‘¥', '3ğ‘¦', '4', '40', '400', '4000', '40000', '4095', '4096', '41', '414', '414141', '416', '417', '42', '420', '4200', '43', '432', '438', '44', '45', '450', '4500', '453', '45t', '46', '466', '46x', '47', '475', '48', '482', '49', '49n', '4_1', '4_2', '4_22xdx', '4_2f', '4_3', '4a', '4a_9', '4ab', '4ac', '4at', '4ax', '4ay', '4b', '4bx', '4c', '4c_0', '4c_2', '4c_2x', '4c_s', '4cy', '4d', '4dividing', '4dx', '4e', '4f', '4g', '4h', '4i', '4if', '4k', '4lnx', '4m', '4n', '4other', '4r', '4s_', '4t', '4th', '4x', '4xdx', '4xy', '4xyz', '4y', '4z', '4z_1z_2z_4', '4z_2', '4ğ‘“', '4ğ‘–', '4ğ‘¥', '4ğ‘¥ğ‘¦', '4ğ‘¦', '5', '50', '500', '5000', '5040', '50a', '50d', '50x', '51', '510', '512', '513', '513x', '52', '520200', '521', '5253', '53', '5346', '5353', '54', '540', '543', '54x', '55', '5500', '56', '561', '567', '567724', '57', '576', '57x', '58', '585', '586', '59', '594', '5_', '5a', '5ax', '5b', '5bx', '5c', '5c_1x', '5i', '5k', '5n', '5p', '5p_3', '5t', '5x', '5xy', '5y', '5ğ‘–', '6', '60', '600', '61', '62', '625', '63', '64', '648', '65', '6561', '66', '660', '68', '69', '6_', '6a', '6ax', '6b', '6c_4', '6i', '6p', '6t', '6x', '6xy', '6y', '6z', '7', '70', '700', '72', '73', '75', '78', '79', '7i', '7n', '7th', '7x', '7y', '8', '80', '81', '82', '83', '84', '85', '87', '88', '89', '8c_r', '8i', '8t', '8x', '8y', '9', '90', '902', '92', '95', '96y', '97', '99', '999', '9_', '9a', '9i', '9th', '9x', '9y', '_', '_0', '_0f', '_0x', '_1', '_2', '_3', '_4', '_5', '___', '____', '_____', '______', '_______', '________', '_________', '__________', '___________', '____________', '_____________', '______________', '_______________', '________________', '_________________', '__________class', '______of', '_ht', '_x', '_ğ‘', 'a', 'a_', 'a_0', 'a_0a_1', 'a_0f', 'a_1', 'a_1a_2', 'a_1x', 'a_2', 'a_2a_3', 'a_2x', 'a_3', 'a_3x', 'a_4', 'a_5', 'a_6', 'a_7', 'a_8', 'a_9', 'a_i', 'a_k', 'a_n', 'a_nx', 'a_of', 'a_p', 'a_q', 'a_r', 'a_x', 'a_y', 'a_z', 'aa', 'ab', 'abbc', 'abbcabbc', 'abc', 'abcd', 'abcdef', 'about', 'above', 'abscissa', 'absolute', 'ac', 'acb', 'acceleration', 'according', 'acid', 'acidic', 'acidity', 'activity', 'actual', 'acute', 'ad', 'add', 'added', 'adding', 'addition', 'addresses', 'adj', 'adjacent', 'adjoining', 'adjoint', 'ae', 'af', 'affixes', 'after', 'ag', 'again', 'against', 'age', 'ahead', 'ai', 'ajay', 'algebraic', 'alike', 'alkalinity', 'all', 'allowed', 'along', 'alpha', 'alpha_', 'alpha_1', 'alpha_2', 'alpha_3', 'alpha_i', 'alpha_ip_1', 'alpha_n', 'alphabet', 'alphabetical', 'also', 'alternate', 'alternately', 'altitude', 'always', 'am', 'among', 'amongst', 'amount', 'amp', 'an', 'and', 'angle', 'angled', 'angles', 'another', 'answer', 'answers', 'ant', 'anti', 'anticlockwise', 'any', 'aob', 'ap', 'apb', 'appear', 'appeared', 'appears', 'apple', 'apples', 'applicable', 'applied', 'applying', 'appropriate', 'appropriately', 'approximate', 'approximated', 'approximately', 'approximation', 'aq', 'ar', 'arbitrarily', 'arbitrary', 'arcs', 'are', 'area', 'areas', 'arg', 'argand', 'argument', 'arithmetic', 'around', 'arrange', 'arranged', 'arrangement', 'arrangements', 'arranging', 'array', 'art', 'as', 'ascending', 'assertion', 'assign', 'assume', 'assumed', 'assumes', 'assuming', 'asymptote', 'asymptotes', 'at', 'atleast', 'attains', 'attempt', 'australian', 'auxiliary', 'available', 'avanti', 'average', 'awarded', 'away', 'ax', 'axes', 'axesdirectrices', 'axesfocilength', 'axis', 'ay', 'az', 'b', 'b_', 'b_1', 'b_1b_2', 'b_1x', 'b_1y', 'b_2', 'b_2x', 'b_2y', 'b_3', 'b_3y', 'b_4', 'b_af', 'b_i', 'b_k', 'b_n', 'b_x', 'b_y', 'b_z', 'ba', 'bac', 'back', 'bad', 'bag', 'ball', 'balls', 'bank', 'bar', 'base', 'based', 'basic', 'basis', 'basketball', 'bc', 'bd', 'bdc', 'be', 'beads', 'bearing', 'because', 'become', 'becomes', 'been', 'before', 'begin', 'beginning', 'behaviour', 'being', 'belong', 'belonging', 'belongs', 'below', 'bent', 'bernoulli', 'best', 'beta', 'beta_1', 'beta_2', 'better', 'between', 'bi', 'biased', 'binary', 'binomial', 'bird', 'bisected', 'bisector', 'bisectors', 'bisects', 'black', 'blank', 'blanks', 'blue', 'board', 'books', 'boolean', 'both', 'bottom', 'bounded', 'box', 'boxes', 'boy', 'boys', 'bp', 'bq', 'breadth', 'bride', 'bring', 'brothers', 'brought', 'bt', 'builder', 'bus', 'but', 'buy', 'bx', 'by', 'bz', 'c', 'c1', 'c2', 'c_', 'c_0', 'c_1', 'c_1c_2', 'c_1x', 'c_1z', 'c_2', 'c_2x', 'c_2z', 'c_3', 'c_3z', 'c_4', 'c_5', 'c_6', 'c_k', 'c_n', 'c_r', 'ca', 'calculate', 'calculated', 'calculating', 'calcutta', 'called', 'can', 'cancelled', 'candidate', 'cannot', 'cant', 'cap', 'capital', 'car', 'card', 'cards', 'carefully', 'carrom', 'cartesian', 'case', 'cases', 'cauchy', 'cd', 'cdo', 'cdot', 'cdot2', 'cdot3', 'cdot4', 'cdot5', 'cdot7', 'center', 'centered', 'centers', 'central', 'centre', 'centred', 'centres', 'centroid', 'century', 'certain', 'cf', 'chance', 'change', 'changed', 'changes', 'changing', 'channel', 'channels', 'charges', 'chatur', 'check', 'chemical', 'chemicals', 'chemists', 'chennai', 'chess', 'child', 'children', 'choice', 'choices', 'choose', 'choosing', 'chord', 'chords', 'chosen', 'circ', 'circle', 'circles', 'circuit', 'circular', 'circum', 'circumcenter', 'circumcentre', 'circumcircle', 'circumference', 'circumradius', 'cities', 'city', 'ck', 'class', 'classes', 'clockwise', 'closed', 'club', 'cm', 'co', 'coaxial', 'codomain', 'coefficient', 'coefficients', 'coin', 'coincide', 'coins', 'cold', 'collection', 'college', 'collinear', 'colors', 'colour', 'colours', 'column', 'columns', 'columnscolumn', 'combination', 'combinations', 'combined', 'come', 'comes', 'comment', 'committee', 'common', 'compared', 'complement', 'complete', 'completed', 'complex', 'component', 'components', 'composite', 'composition', 'compound', 'compute', 'computed', 'concentration', 'concentric', 'concept', 'conclude', 'concurrency', 'concurrent', 'condition', 'conditional', 'conditions', 'cone', 'congruent', 'conic', 'conics', 'conjugate', 'conjunction', 'connected', 'consecutive', 'consecutively', 'consider', 'considered', 'consistent', 'consisting', 'consists', 'consonant', 'consonants', 'constant', 'constants', 'constructed', 'contact', 'contain', 'contained', 'containing', 'contains', 'content', 'contingency', 'continues', 'continuity', 'continuous', 'contradiction', 'contrapositive', 'converse', 'convert', 'coordinate', 'coordinates', 'coplanar', 'coprime', 'correct', 'correctly', 'corresponding', 'cos', 'cos2', 'cos2x', 'cos2y', 'cos3', 'cos3x', 'cos4', 'cos4x', 'cos5', 'cosec', 'cosecx', 'cosines', 'cosx', 'cot', 'cot2x', 'could', 'counter', 'cover', 'covered', 'covers', 'cp', 'cq', 'cr', 'create', 'created', 'creating', 'cricket', 'critical', 'crosses', 'cube', 'cubes', 'cubic', 'cup', 'current', 'curve', 'curves', 'cut', 'cuts', 'cx', 'cy', 'cyclic', 'cylinder', 'cylindrical', 'cz', 'd', 'd_1', 'd_2', 'da', 'dark', 'data', 'date', 'day', 'days', 'db', 'dc', 'de', 'decided', 'decimal', 'decreased', 'decreases', 'decreasing', 'defective', 'define', 'defined', 'definite', 'degree', 'degrees', 'delhi', 'delta', 'denote', 'denoted', 'denotes', 'depend', 'dependent', 'derivable', 'derivative', 'derivatives', 'described', 'describes', 'det', 'determinant', 'determine', 'determined', 'deviation', 'deviations', 'df', 'diagonal', 'diagonals', 'diagram', 'diagrams', 'diameter', 'diameters', 'dice', 'dictionaries', 'dictionary', 'did', 'die', 'differ', 'difference', 'different', 'differentiability', 'differentiable', 'differential', 'differentiate', 'differentiation', 'digit', 'digits', 'dimension', 'dimensional', 'dine', 'dinner', 'direct', 'direction', 'directions', 'director', 'directrices', 'directrix', 'disc', 'discontinuity', 'discontinuous', 'discriminant', 'discriminants', 'discuss', 'disjoint', 'disorder', 'displacement', 'distance', 'distances', 'distinct', 'distributed', 'distributing', 'distribution', 'distributions', 'divide', 'divided', 'divides', 'dividing', 'divisible', 'division', 'divisor', 'divisors', 'do', 'does', 'doing', 'doll', 'dolls', 'domain', 'done', 'dot', 'double', 'doubled', 'down', 'downwards', 'dp', 'draw', 'drawing', 'drawn', 'dropbox', 'dt', 'dual', 'due', 'dummy', 'during', 'dx', 'dy', 'e', 'e_1', 'e_2', 'each', 'east', 'eccentric', 'eccentricities', 'eccentricity', 'eccentricityverticesequation', 'edges', 'efficient', 'eight', 'eighth', 'either', 'element', 'elementary', 'elements', 'elevation', 'eleven', 'ell', 'ellipse', 'ellipses', 'employee', 'empty', 'enclosed', 'end', 'ends', 'english', 'enrolled', 'ensure', 'enter', 'entries', 'entry', 'envelope', 'envelopes', 'equal', 'equality', 'equally', 'equals', 'equation', 'equations', 'equidistant', 'equilateral', 'equiv', 'equivalence', 'equivalent', 'eraser', 'erasers', 'error', 'errors', 'euler', 'evaluate', 'even', 'event', 'events', 'every', 'everywhere', 'ex', 'exact', 'exactly', 'examination', 'example', 'exceed', 'exceeds', 'except', 'excluding', 'exclusive', 'exhaustive', 'exist', 'exists', 'expand', 'expanded', 'expansion', 'experiment', 'exponent', 'exponential', 'exponents', 'exposed', 'express', 'expressed', 'expression', 'expressions', 'externally', 'extreme', 'extremities', 'extremity', 'f', 'f_1', 'f_2', 'f_3', 'f_4', 'f_6', 'f_i', 'f_k', 'f_n', 'face', 'faces', 'fact', 'factor', 'factors', 'factory', 'failure', 'fair', 'fallacy', 'falls', 'fals', 'false', 'falseness', 'families', 'family', 'farthest', 'fastest', 'father', 'february', 'feet', 'fellows', 'fifth', 'figure', 'figures', 'fill', 'final', 'finally', 'find', 'finding', 'finds', 'finite', 'fire', 'first', 'five', 'fixed', 'flies', 'floor', 'flowers', 'focal', 'foci', 'focii', 'focus', 'fog', 'folded', 'folder', 'follow', 'following', 'follows', 'foot', 'football', 'for', 'forall', 'form', 'formed', 'forming', 'forms', 'formula', 'formulae', 'found', 'four', 'fourth', 'frac', 'frac1', 'frac12', 'frac13', 'frac14', 'frac16', 'frac1x', 'frac2', 'frac23', 'frac25', 'frac2x', 'frac3', 'frac32', 'frac34f', 'frac43', 'frac8', 'fraction', 'fractional', 'fractions', 'free', 'french', 'frequencies', 'frequency', 'friend', 'friends', 'from', 'function', 'functioniiiiiiiv', 'functionquadrantsign', 'functions', 'further', 'fy', 'g', 'g_1', 'g_2', 'g_3', 'g_n', 'game', 'games', 'gamma', 'garland', 'gathered', 'ge', 'ge0', 'ge1', 'ge2', 'ge3', 'ge5', 'ge6', 'ge7', 'general', 'generated', 'gentlemen', 'geometric', 'geq', 'geq0', 'gets', 'getting', 'gift', 'giftramyesnonoshyamyesyesyesmohannoyesyessohanyesnoyessitayesyesyesgitanononoanswer', 'giftramyesnonoshyamyesyesyesmohannoyesyessohanyesnoyessitayesyesyesgitanononogiven', 'giftramyesnonoshyamyesyesyesmohannoyesyessohanyesnoyessitayesyesyesgitanononolet', 'girl', 'girls', 'gita', 'give', 'given', 'gives', 'giving', 'global', 'gm', 'go', 'goals', 'goes', 'gof', 'going', 'good', 'got', 'gp', 'gradient', 'graph', 'graphically', 'graphs', 'greater', 'greatest', 'green', 'groom', 'ground', 'group', 'grouped', 'groups', 'gt', 'guest', 'guestbride', 'guestbrought', 'guests', 'h', 'h_', 'h_1', 'h_2', 'h_n', 'had', 'half', 'hand', 'handsome', 'happens', 'harmonic', 'has', 'hat', 'have', 'having', 'hcf', 'he', 'head', 'heads', 'height', 'her', 'here', 'hexagon', 'high', 'higher', 'highest', 'him', 'his', 'hit', 'hits', 'hitting', 'hold', 'holds', 'holiday', 'holidays', 'homogeneous', 'homogenous', 'honest', 'horizontal', 'horizontally', 'hospital', 'host', 'hour', 'hours', 'house', 'how', 'hp', 'ht', 'hundred', 'hydrogen', 'hyperbola', 'hyperbolas', 'i', 'i2', 'i_', 'i_1', 'i_2', 'i_3', 'i_4', 'i_n', 'ia', 'ib', 'ib_k', 'ic', 'ice', 'icolumn', 'id', 'identical', 'identify', 'identities', 'identity', 'ie', 'if', 'iff', 'ig', 'ii', 'iicolumn', 'iii', 'iiif', 'iiin', 'iithe', 'ij', 'ilist', 'im', 'image', 'images', 'imaginary', 'implicit', 'implies', 'in', 'incentre', 'incidence', 'incident', 'incircle', 'inclined', 'included', 'including', 'inclusive', 'income', 'incorrect', 'increase', 'increased', 'increases', 'increasing', 'indefinite', 'indefinitely', 'independent', 'indeterminate', 'index', 'india', 'indian', 'individual', 'individuals', 'indoor', 'inequalities', 'inequality', 'inequation', 'inequations', 'infinite', 'infinitely', 'infinity', 'inflection', 'information', 'infty', 'initial', 'injective', 'inradius', 'inscribed', 'insert', 'inserted', 'inside', 'instant', 'instantaneous', 'int', 'int_', 'int_0', 'int_1', 'integer', 'integers', 'integral', 'integrating', 'integration', 'intercept', 'intercepted', 'intercepts', 'interchanged', 'interior', 'intermediate', 'internal', 'internally', 'intersect', 'intersected', 'intersecting', 'intersection', 'intersects', 'interval', 'intervals', 'into', 'inverse', 'invertible', 'invite', 'invited', 'ions', 'iron', 'irrational', 'irremovable', 'is', 'isdiscontinuous', 'iseven', 'isodd', 'isosceles', 'it', 'item', 'items', 'its', 'itself', 'iv', 'ive', 'ix', 'iy', 'iz', 'j', 'join', 'joining', 'joint', 'jumbling', 'just', 'k', 'k_', 'k_1', 'k_2', 'ka', 'kb', 'keeping', 'kept', 'ki', 'km', 'kn', 'know', 'known', 'kolkata', 'kx', 'ky', 'l', 'l_1', 'l_2', 'l_3', 'ladder', 'ladies', 'lagrange', 'lambda', 'large', 'larger', 'largest', 'last', 'later', 'lateral', 'latus', 'latusrectum', 'law', 'laws', 'layer', 'lcm', 'ldots', 'le', 'le0', 'le1', 'le10', 'le2', 'le20', 'le2x', 'le3', 'le4', 'le5', 'le6', 'le8', 'leading', 'learnt', 'least', 'leaves', 'left', 'leftrightarrow', 'legs', 'length', 'lengths', 'leq', 'leq0', 'leq1', 'leq4', 'leq6', 'less', 'let', 'letter', 'letters', 'level', 'liate', 'lie', 'lies', 'light', 'like', 'likely', 'lim', 'limit', 'limiting', 'limits', 'limits_', 'limits_0', 'line', 'linear', 'linearly', 'lines', 'list', 'live', 'living', 'lm', 'ln', 'local', 'locate', 'located', 'locus', 'log', 'log2', 'log3', 'log5', 'log_', 'log_2', 'log_215', 'log_23', 'log_25', 'log_27', 'log_2x', 'log_2z', 'log_3', 'log_32', 'log_35', 'log_360', 'log_3x', 'log_3y', 'log_4', 'log_460', 'log_48', 'log_4x', 'log_5', 'log_52', 'log_560', 'log_5x', 'log_6', 'log_a', 'log_abc', 'log_ax', 'log_b', 'log_b4', 'log_ba', 'log_bca', 'log_bx', 'log_cab', 'log_e', 'log_ex', 'log_mn', 'log_x5', 'logarithm', 'logarithmic', 'logarithms', 'logic', 'logical', 'logically', 'long', 'longest', 'longleftrightarrow', 'longrightarrow', 'longrightarrow0', 'losing', 'loss', 'lower', 'lt', 'lx', 'lying', 'm', 'm_', 'm_1', 'm_2', 'ma', 'made', 'magnitude', 'maharashtra', 'major', 'make', 'makes', 'making', 'man', 'mangoes', 'manufacturer', 'many', 'mark', 'marked', 'marks', 'match', 'matches', 'matching', 'math', 'mathbb', 'mathematical', 'mathematics', 'mathop', 'maths', 'matrices', 'matrix', 'max', 'maxima', 'maximum', 'may', 'mayur', 'mb', 'mean', 'meaning', 'meaningful', 'meanings', 'means', 'measure', 'measured', 'measuring', 'medals', 'median', 'medians', 'meet', 'meeting', 'meets', 'member', 'members', 'men', 'mention', 'mentioned', 'meters', 'method', 'metres', 'mid', 'middle', 'midpoint', 'midpoints', 'milk', 'min', 'minima', 'minimum', 'minor', 'minute', 'minutes', 'mirror', 'misses', 'missing', 'mississippi', 'mixing', 'mixture', 'mm', 'mn', 'mode', 'modular', 'modulus', 'mohan', 'money', 'monotonic', 'monotonically', 'month', 'monthly', 'months', 'more', 'morning', 'most', 'motion', 'move', 'moved', 'moves', 'movie', 'moving', 'mp', 'mr', 'mu', 'much', 'multiple', 'multiples', 'multiplied', 'multiplying', 'mumbai', 'music', 'must', 'mutually', 'mx', 'my', 'n', 'n_', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'na', 'nail', 'nails', 'namegroom', 'namely', 'natural', 'nature', 'nc', 'nc_', 'nc_0', 'nc_1', 'nc_2', 'nc_3', 'nc_4', 'nc_7', 'nc_n', 'nc_r', 'nc_s', 'nd', 'ndx', 'ne', 'ne0', 'ne1', 'ne2', 'nearest', 'necessarily', 'necessary', 'necklace', 'need', 'needed', 'needs', 'negation', 'negative', 'neglected', 'neither', 'neq', 'neutral', 'never', 'new', 'news', 'next', 'nf', 'ng', 'nine', 'no', 'non', 'none', 'nonzero', 'nor', 'normal', 'normals', 'north', 'not', 'notation', 'notations', 'note', 'notin', 'novels', 'now', 'np', 'np_n', 'np_r', 'nth', 'null', 'number', 'numbered', 'numbers', 'numerical', 'numerically', 'nuts', 'nx', 'o', 'oa', 'oab', 'oabc', 'oal', 'ob', 'obc', 'object', 'objects', 'obm', 'observation', 'observations', 'observed', 'obtain', 'obtained', 'obtuse', 'oc', 'oca', 'occupy', 'occur', 'occurring', 'occurs', 'ocn', 'octagon', 'od', 'odd', 'of', 'off', 'og_1', 'og_2', 'og_3', 'old', 'omega', 'on', 'once', 'one', 'only', 'onto', 'op', 'open', 'operation', 'operations', 'operator', 'opposite', 'opq', 'opqr', 'oprq', 'option', 'options', 'oq', 'or', 'oranges', 'order', 'ordered', 'ordinary', 'ordinate', 'ordinates', 'origin', 'original', 'orthocenter', 'orthocentre', 'orthogonal', 'orthogonally', 'os', 'other', 'out', 'outcomes', 'outside', 'over', 'overline', 'overrightarrow', 'own', 'ox', 'oy', 'oz', 'p', 'p_', 'p_1', 'p_1x', 'p_2', 'p_3', 'p_n', 'pa', 'pab', 'pack', 'paid', 'painted', 'painting', 'pair', 'pairs', 'parabola', 'parabolas', 'paragraph', 'parallel', 'parallelogram', 'parallelograms', 'parallelopiped', 'parameter', 'parameters', 'parametric', 'parametrically', 'part', 'partial', 'particle', 'particular', 'partition', 'partitioned', 'parts', 'party', 'pass', 'passage', 'passed', 'passes', 'passing', 'path', 'pb', 'pbc', 'pca', 'pencil', 'pencils', 'people', 'per', 'percentage', 'perfect', 'perimeter', 'period', 'periodic', 'permutation', 'permutations', 'permuting', 'perpendicular', 'perpendiculars', 'person', 'persons', 'pf_1f_2', 'pg', 'ph', 'phi', 'phone', 'physics', 'pi', 'pi2', 'picked', 'picnic', 'pineapple', 'pk', 'place', 'placed', 'places', 'plane', 'planes', 'plant', 'plants', 'play', 'played', 'player', 'players', 'playing', 'plays', 'please', 'plot', 'pm', 'pm5', 'pmi', 'pn', 'pocket', 'point', 'points', 'polar', 'pole', 'poles', 'polygon', 'polynomial', 'polynomials', 'population', 'portal', 'portion', 'position', 'positions', 'positive', 'possess', 'possesses', 'possible', 'possibly', 'post', 'power', 'powers', 'pq', 'pqr', 'pqrs', 'pqs', 'pr', 'present', 'presented', 'previous', 'primary', 'prime', 'principal', 'printing', 'probabilities', 'probability', 'problem', 'problems', 'process', 'prod', 'produced', 'product', 'products', 'progression', 'projection', 'promised', 'proper', 'properties', 'property', 'proportion', 'proportional', 'proposition', 'prove', 'ps', 'psq', 'pt', 'ptn', 'pure', 'purely', 'put', 'px', 'py', 'pyramid', 'q', 'q1', 'q2', 'q3', 'q_', 'q_n', 'qa', 'qb', 'qr', 'qrs', 'qs', 'quadrant', 'quadrantsign', 'quadratic', 'quadric', 'quadrilateral', 'quadrilaterals', 'quantifier', 'quantifiers', 'quantity', 'question', 'questions', 'queue', 'quotient', 'qx', 'qy', 'r', 'r_1', 'r_2', 'r_3', 'race', 'radian', 'radians', 'radical', 'radii', 'radius', 'raining', 'ram', 'ranchod', 'random', 'randomly', 'range', 'rate', 'ratio', 'rational', 'rationalize', 'rationals', 'ratios', 'ray', 'rays', 'rc_k', 'rd', 're', 'reach', 'reached', 'reaches', 'reaching', 'read', 'real', 'reals', 'rearrange', 'reason', 'reasoning', 'recall', 'receive', 'received', 'receiving', 'recent', 'reciprocal', 'reciprocals', 'record', 'recorded', 'records', 'recta', 'rectangle', 'rectangles', 'rectangular', 'rectum', 'rectums', 'red', 'reduced', 'referred', 'refers', 'reflected', 'reflection', 'reflects', 'reflexive', 'refuses', 'regarding', 'region', 'regions', 'regionsexpressionregion', 'registration', 'regular', 'related', 'relation', 'relations', 'relationship', 'relative', 'relatively', 'relatives', 'reloads', 'remain', 'remainder', 'remaining', 'remains', 'removed', 'renowned', 'rent', 'repaying', 'repeat', 'repeated', 'repeats', 'repetition', 'replace', 'replaced', 'replacement', 'reported', 'represent', 'representation', 'represented', 'representing', 'represents', 'reproduced', 'required', 'requirement', 'research', 'resemble', 'resp', 'respect', 'respective', 'respectively', 'rest', 'restarts', 'resting', 'restrictions', 'rests', 'result', 'resultant', 'resulted', 'resulting', 'results', 'retail', 'retaining', 'returned', 'reversing', 'revision', 'revolution', 'revolutions', 'rf', 'rgi', 'rhe', 'rhombus', 'rich', 'righ', 'right', 'rightarrow', 'rightarrow0', 'rightarrow1', 'rightarrow2', 'rightarrow3', 'rim', 'ring', 'rings', 'rm', 'rn', 'road', 'rod', 'rohit', 'roles', 'roll', 'rolle', 'rolled', 'room', 'root', 'roots', 'rootsequal', 'rootsno', 'roses', 'roster', 'rotated', 'rotation', 'round', 'rounder', 'route', 'routes', 'row', 'rows', 'rp', 'rp_r', 'rpm', 'rpq', 'rq', 'rqp', 'rs', 'rule', 'rules', 'run', 'running', 'runs', 'rusted', 'rx', 'ry', 'rz', 's', 's3', 's_', 's_1', 's_1s_2s_3s_4', 's_2', 's_3', 's_4', 's_k', 's_n', 's_r', 's_x', 'sachin', 'saharanpur', 'said', 'sailboat', 'sailboats', 'salary', 'sale', 'sales', 'salesman', 'same', 'sample', 'samples', 'sanskrit', 'satisfied', 'satisfies', 'satisfy', 'satisfying', 'say', 'scalar', 'scalars', 'scale', 'school', 'schoolii', 'science', 'scientific', 'scientists', 'score', 'scored', 'scores', 'scrabble', 'seat', 'seated', 'seats', 'sec', 'sec0', 'sec2', 'sec300', 'sec4', 'sec90', 'second', 'seconds', 'section', 'sections', 'sector', 'secx', 'secxtanxdx', 'secğœƒ', 'seems', 'seen', 'segment', 'segments', 'select', 'selected', 'selecting', 'selection', 'selections', 'self', 'semi', 'send', 'seniors', 'sense', 'sent', 'sentence', 'sentences', 'separated', 'september', 'sequence', 'sequences', 'serial', 'series', 'servant', 'service', 'session', 'set', 'sets', 'seven', 'seventh', 'sgn', 'shaded', 'shadow', 'shall', 'shaped', 'shapes', 'shares', 'sharp', 'she', 'sheet', 'sheets', 'shelf', 'shift', 'shifted', 'shifts', 'shooting', 'shop', 'short', 'shortest', 'shot', 'should', 'show', 'showing', 'shown', 'shows', 'shuffled', 'shyam', 'side', 'sided', 'sides', 'sigma', 'sigma_', 'sign', 'signs', 'signum', 'silvia', 'sim', 'similarities', 'simple', 'simplest', 'simplified', 'simplifies', 'simplify', 'simply', 'simultaneously', 'sin', 'sin1', 'sin175', 'sin2', 'sin23', 'sin275', 'sin2a', 'sin2b', 'sin2t', 'sin2tdt', 'sin2x', 'sin3', 'sin3x', 'sin4', 'sin46', 'sin4a', 'sin5', 'sin5x', 'sin62', 'sin7', 'sin74', 'sin75', 'sin8', 'since', 'sine', 'sines', 'single', 'singleton', 'singular', 'sinx', 'sinxdx', 'sinğ›¼', 'sisters', 'sit', 'sita', 'sits', 'sitting', 'situated', 'situations', 'six', 'sixteen', 'size', 'sizes', 'sketching', 'skew', 'skewed', 'skin', 'sky', 'slack', 'sleep', 'slide', 'slides', 'sliding', 'slightly', 'slope', 'slopes', 'smae', 'small', 'smaller', 'smallest', 'smarter', 'smoke', 'snake', 'snowing', 'snowingstatement', 'so', 'sohan', 'solid', 'solution', 'solutions', 'solve', 'solving', 'some', 'somehow', 'sometimes', 'sometimesii', 'sons', 'sound', 'source', 'south', 'sove', 'sovereigns', 'sp', 'space', 'spaces', 'spade', 'spades', 'speak', 'species', 'specific', 'specified', 'speed', 'sphere', 'spherical', 'sports', 'sq', 'sqrt', 'sqrt2', 'sqrt3', 'sqrt3i', 'sqrt5', 'sqrt7', 'square', 'squares', 'st', 'stand', 'standard', 'standing', 'stands', 'start', 'starting', 'starts', 'state', 'statement', 'statements', 'states', 'stations', 'statistics', 'std', 'steer', 'step', 'steps', 'stock', 'stone', 'stones', 'stop', 'stops', 'store', 'storing', 'straight', 'strawberry', 'streets', 'strict', 'strictly', 'strikes', 'stripes', 'strong', 'strongthen', 'student', 'students', 'students5871218the', 'studied', 'study', 'sub', 'subject', 'subjects', 'subsequent', 'subset', 'subsets', 'substance', 'substitute', 'substitution', 'subtend', 'subtended', 'subtends', 'succeeds', 'success', 'successes', 'successive', 'successively', 'such', 'sufficient', 'suffixes', 'suggest', 'suit', 'suitable', 'suits', 'sum', 'sum_', 'suman', 'summation', 'sums', 'sun', 'sunday', 'sundays', 'superset', 'supose', 'supply', 'suppose', 'supposing', 'suresh', 'surface', 'suriti', 'survey', 'surveyed', 'surviving', 'sv', 'sweets', 'symbol', 'symbolic', 'symbolically', 'symbols', 'symmetric', 'symmetrical', 'symmetrically', 'system', 'systems', 't', 't2', 't_', 't_0', 't_1', 't_1t_2', 't_1t_2t_5', 't_2', 't_3', 't_4', 't_5', 't_7', 't_k', 't_m', 't_n', 't_r', 'ta', 'table', 'tables', 'tabular', 'tail', 'tails', 'take', 'taken', 'takes', 'taking', 'tall', 'tan', 'tan1', 'tan1024', 'tan15', 'tan190', 'tan2', 'tan20', 'tan2a', 'tan2x', 'tan3', 'tan30', 'tan3a', 'tan3x', 'tan4', 'tan4x', 'tan50', 'tan5x', 'tan6t', 'tan7', 'tan70', 'tan89', 'tangency', 'tangent', 'tangents', 'tanx', 'tanğ›¼', 'tanğœƒ', 'tarb', 'target', 'tatanagar', 'tautologies', 'tautology', 'tb', 'tdt', 'teach', 'teacher', 'teachers', 'teaching', 'team', 'teams', 'tear', 'techniques', 'teeth', 'temperature', 'temporary', 'ten', 'tendency', 'tends', 'tennis', 'tenth', 'term', 'termed', 'termi', 'termiii', 'terminal', 'termiv', 'terms', 'terms1', 'termwhich', 'test', 'tests', 'tetrahedrin', 'tetrahedron', 'text', 'th', 'than', 'that', 'thatmakes', 'the', 'thee', 'their', 'theirs', 'theletters', 'them', 'themselves', 'then', 'thenif', 'thenmaximum', 'thennumber', 'thenroots', 'thenthe', 'thenvalue', 'theorem', 'theorems', 'there', 'therefore', 'thesame', 'these', 'theta', 'theta2', 'theta_0', 'theta_0z', 'theta_1', 'theta_1z', 'theta_2', 'theta_3', 'theta_4', 'theta_i', 'theta_n', 'they', 'thick', 'thickness', 'things', 'third', 'thirteen', 'this', 'thne', 'those', 'though', 'three', 'thrice', 'through', 'throughout', 'throw', 'throwing', 'thrown', 'throws', 'thus', 'till', 'time', 'times', 'times2', 'times243', 'times3', 'times4', 'times5', 'times6', 'times7', 'tip', 'to', 'to0', 'to1', 'to2', 'to2a', 'to3', 'to3if', 'to4', 'today', 'together', 'toi', 'too', 'took', 'top', 'toss', 'tossed', 'tosses', 'tossing', 'total', 'touch', 'touched', 'touches', 'touching', 'tourist', 'tournament', 'towards', 'tower', 'town', 'toy', 'toys', 'tpq', 'trace', 'traces', 'track', 'train', 'transfer', 'transferred', 'transformation', 'transformations', 'transformed', 'transforms', 'transitive', 'translated', 'transpose', 'transverse', 'trapezium', 'travel', 'travelled', 'traveller', 'travelling', 'travels', 'traverse', 'tree', 'trial', 'trials', 'triangle', 'triangles', 'triangular', 'tries', 'trigonometric', 'trip', 'triple', 'triples', 'triplet', 'triplets', 'trisected', 'trivial', 'true', 'trueii', 'trueiii', 'truethere', 'truth', 'truthfulness', 'try', 'ts', 'tt', 'tulips', 'turbo', 'turn', 'turned', 'turns', 'twelve', 'twenty', 'twice', 'two', 'twoparticular', 'tx', 'type', 'types', 'u', 'u_1', 'u_2', 'u_3', 'u_n', 'uf', 'unable', 'unbiased', 'unchanged', 'uncommon', 'under', 'undergoes', 'underline', 'underneath', 'understand', 'understood', 'unequal', 'ungrouped', 'uni', 'uniform', 'unimodular', 'unique', 'uniquely', 'unit', 'united', 'units', 'unitsin', 'unity', 'universal', 'unknown', 'unlimited', 'unordered', 'unreadable', 'until', 'up', 'upon', 'upper', 'upto', 'upward', 'upwards', 'urn', 'urns', 'us', 'use', 'used', 'using', 'usual', 'v', 'v_1', 'v_2', 'valid', 'value', 'valued', 'values', 'vanilla', 'vanishes', 'var', 'variability', 'variable', 'variables', 'variance', 'variate', 'variation', 'varies', 'vary', 'varying', 'vec', 'vector', 'vectors', 'vee', 'velocity', 'venn', 'verbal', 'vertex', 'vertical', 'vertically', 'vertices', 'very', 'vi', 'via', 'vice', 'viii', 'vijay', 'violet', 'virat', 'visible', 'volume', 'vote', 'voter', 'vowel', 'vowels', 'w', 'wages', 'wagesrs', 'waits', 'walking', 'wall', 'want', 'was', 'watch', 'water', 'wavy', 'way', 'ways', 'we', 'wearing', 'wedding', 'wedge', 'week', 'weeks', 'weighs', 'weight', 'weights', 'well', 'went', 'were', 'what', 'whatever', 'wheel', 'wheels', 'when', 'where', 'whereas', 'whether', 'which', 'while', 'white', 'who', 'whole', 'whom', 'whose', 'widehat', 'width', 'wife', 'will', 'win', 'windy', 'winner', 'winning', 'wins', 'wire', 'wish', 'with', 'within', 'without', 'wolf', 'woman', 'women', 'word', 'words', 'work', 'workers', 'world', 'worn', 'would', 'write', 'writes', 'writing', 'written', 'wrong', 'wrongly', 'wrt', 'wz', 'x', 'x1', 'x2', 'x4', 'x5', 'x_', 'x_0', 'x_0f', 'x_1', 'x_1t', 'x_1x_2', 'x_1y', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_9', 'x_af', 'x_i', 'x_k', 'x_n', 'xa', 'xb', 'xdx', 'xdy', 'xe', 'xf', 'xg', 'xi', 'xii', 'xk', 'xr', 'xt', 'xtanx', 'xx', 'xy', 'xy_2', 'xyz', 'xyzwu', 'xz', 'y', 'y2', 'y3', 'y_', 'y_0', 'y_1', 'y_1y_2', 'y_2', 'y_3', 'y_4', 'y_i', 'y_k', 'y_n', 'yb', 'yc', 'ydx', 'ye', 'year', 'years', 'yearwhich', 'yellow', 'yes', 'yi', 'yields', 'you', 'your', 'yourself', 'yr', 'yx', 'yy', 'yz', 'z', 'z1', 'z_', 'z_0', 'z_1', 'z_1z_2', 'z_1z_2z_3', 'z_2', 'z_3', 'z_4', 'z_8', 'z_9', 'z_i', 'z_j', 'z_k', 'z_n', 'ze', 'zero', 'zeroes', 'zeroiii', 'zeros', 'zr', 'zw', 'zx', 'ğ´', 'ğ´_1', 'ğ´_2', 'ğ´ğµ', 'ğ´ğ‘˜ğ‘ ', 'ğµ', 'ğµ_1', 'ğµ_2', 'ğµ_3', 'ğµ_4', 'ğµğ¶', 'ğ¶', 'ğ¶_0', 'ğ¶_1', 'ğ¶_2', 'ğ¶_3', 'ğ¶_4', 'ğ¶_8', 'ğ¶_ğ‘›', 'ğ¶_ğ‘Ÿ', 'ğ¶ğ·', 'ğ¶ğ¹', 'ğ·', 'ğ¸', 'ğ¸_1', 'ğ¸_2', 'ğ¸_ğ‘›', 'ğ¹', 'ğº', 'ğº_1', 'ğº_2', 'ğ¼', 'ğ¾', 'ğ¾ğ‘¢ğ‘šğ‘ğ‘Ÿ', 'ğ¿', 'ğ¿_1', 'ğ¿_2', 'ğ‘€', 'ğ‘', 'ğ‘‚', 'ğ‘ƒ', 'ğ‘ƒğ‘†', 'ğ‘„', 'ğ‘…', 'ğ‘…_ğ‘–', 'ğ‘†', 'ğ‘†_1', 'ğ‘†_2', 'ğ‘†_3', 'ğ‘†_4', 'ğ‘†ğ‘†_1', 'ğ‘†ğ‘ğ‘™ğ‘šğ‘ğ‘›', 'ğ‘‡', 'ğ‘‡_', 'ğ‘‡_ğ‘Ÿ', 'ğ‘‰ğ‘ğ‘Ÿ', 'ğ‘Š', 'ğ‘Šğ‘…ğ‘‚ğºğ‘', 'ğ‘‹', 'ğ‘Œ', 'ğ‘', 'ğ‘', 'ğ‘_1', 'ğ‘_1ğ‘¥', 'ğ‘_2', 'ğ‘_2ğ‘¥', 'ğ‘_3', 'ğ‘ğ‘ğ‘', 'ğ‘ğ‘‘ğ‘—', 'ğ‘ğ‘‘ğ‘—ğ´', 'ğ‘ğ‘“', 'ğ‘ğ‘–', 'ğ‘ğ‘›', 'ğ‘ğ‘¥', 'ğ‘ğ‘¦', 'ğ‘', 'ğ‘_1', 'ğ‘_1ğ‘¦', 'ğ‘_2', 'ğ‘_2ğ‘¦', 'ğ‘_3', 'ğ‘ğ‘“', 'ğ‘ğ‘–', 'ğ‘ğ‘¥', 'ğ‘ğ‘¦', 'ğ‘', 'ğ‘_1', 'ğ‘_2', 'ğ‘_3', 'ğ‘_4', 'ğ‘_5', 'ğ‘ğ‘š', 'ğ‘‘', 'ğ‘‘_1', 'ğ‘‘_2', 'ğ‘‘_3', 'ğ‘‘ğ‘¡', 'ğ‘‘ğ‘¥', 'ğ‘‘ğ‘¦', 'ğ‘‘ğœƒ', 'ğ‘’', 'ğ‘“', 'ğ‘”', 'ğ‘–', 'ğ‘–ğ‘‘', 'ğ‘–ğ‘ ', 'ğ‘–ğ‘¦', 'ğ‘˜', 'ğ‘˜ğ‘…_ğ‘–', 'ğ‘˜ğ‘…_ğ‘—', 'ğ‘˜ğ‘Ÿ', 'ğ‘˜ğ‘§', 'ğ‘š', 'ğ‘š_1', 'ğ‘š_2', 'ğ‘šğ‘…ğ‘›', 'ğ‘šğ‘–ğ‘›', 'ğ‘šğ‘¥', 'ğ‘›', 'ğ‘›ğ‘–', 'ğ‘', 'ğ‘_ğ‘–', 'ğ‘ğ‘¥', 'ğ‘', 'ğ‘ğ‘¥', 'ğ‘Ÿ', 'ğ‘Ÿ_1', 'ğ‘Ÿ_2', 'ğ‘Ÿ_3', 'ğ‘Ÿğ‘¢ğ‘˜', 'ğ‘ ', 'ğ‘¡', 'ğ‘¡ğ‘“', 'ğ‘¢ğ‘›ğ‘–ğ‘¡', 'ğ‘£', 'ğ‘£ğ‘¥', 'ğ‘¥', 'ğ‘¥_1', 'ğ‘¥_ğ‘–', 'ğ‘¥ğ‘¦', 'ğ‘¦', 'ğ‘¦_1', 'ğ‘§', 'ğ‘§_1', 'ğ‘§_2', 'ğ›¼', 'ğ›½', 'ğœƒ', 'ğœ†', 'ğœ†ğ‘¥', 'ğœ†ğ‘¦', 'ğœ‹', 'ğœ”']\n"
     ]
    }
   ],
   "source": [
    "x = count_vect.vocabulary_\n",
    "y = list(x.keys() )\n",
    "print(sorted(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cochin',\n",
       " 'erasing',\n",
       " 'languages',\n",
       " 'leads',\n",
       " 'frac1k',\n",
       " '6k',\n",
       " 'paths',\n",
       " 'hens',\n",
       " '680',\n",
       " 'infer',\n",
       " 'nj',\n",
       " 'leq8',\n",
       " 'df_2',\n",
       " 'crew',\n",
       " 'oi',\n",
       " 'split',\n",
       " 'activitythere',\n",
       " 'bm',\n",
       " 'convex',\n",
       " 'legal',\n",
       " 'accessible',\n",
       " 'log_ka',\n",
       " 'propertyif',\n",
       " 'narrow',\n",
       " '2ğœƒ',\n",
       " 'buddh',\n",
       " 'ibt',\n",
       " 'occupied',\n",
       " 'a_1y',\n",
       " 'madrid',\n",
       " '2ğ‘',\n",
       " '850',\n",
       " 'indigo',\n",
       " 'a_1a_',\n",
       " 'cms',\n",
       " 'iiconsider',\n",
       " 'absence',\n",
       " '1figure',\n",
       " 'delta_3',\n",
       " 'log_28',\n",
       " 'adjacently',\n",
       " '729',\n",
       " 'gave',\n",
       " 'bell',\n",
       " 'distributionclasses',\n",
       " 'cars',\n",
       " '9e',\n",
       " 'spanish',\n",
       " 'election',\n",
       " 'multiply',\n",
       " 'hands',\n",
       " 'k2',\n",
       " 'pessimistic',\n",
       " 'gd',\n",
       " 'licence',\n",
       " '93',\n",
       " 'mc_0',\n",
       " 'extended',\n",
       " 'marathi',\n",
       " 'staircase',\n",
       " 'g_1g_2',\n",
       " 'junction',\n",
       " 'hypotenuse',\n",
       " 'lemons',\n",
       " 'spot',\n",
       " 'log_n128',\n",
       " '_0e',\n",
       " 'arctan',\n",
       " 'psi',\n",
       " 'abcx',\n",
       " 'agrees',\n",
       " '96',\n",
       " 'orders',\n",
       " '_____________________',\n",
       " 'rapidly',\n",
       " 'b_s',\n",
       " 'hh',\n",
       " 'dealt',\n",
       " 'kq',\n",
       " 'oabcd',\n",
       " 'algebra',\n",
       " 'encounter',\n",
       " 'log_3a',\n",
       " 'dance',\n",
       " 'applicants',\n",
       " 'closest',\n",
       " 'male',\n",
       " 'weekii',\n",
       " 'log_20',\n",
       " 'cos2048',\n",
       " 'differentiablenot',\n",
       " 'tent',\n",
       " 'log_53',\n",
       " '7c_5',\n",
       " 'illness',\n",
       " 'c_nx',\n",
       " 'le18',\n",
       " '34x',\n",
       " 'factorized',\n",
       " 'concluded',\n",
       " 'beside',\n",
       " 'qp',\n",
       " 'pi_0',\n",
       " 'ge8',\n",
       " 'cos4t',\n",
       " 'accommodate',\n",
       " 'inviting',\n",
       " '2ğ‘¥ğ‘¦',\n",
       " 'cot3x',\n",
       " 'bhushan',\n",
       " 'june',\n",
       " 'expanding',\n",
       " '6a_8',\n",
       " '7c_k',\n",
       " 'quartile',\n",
       " 'magnitudes',\n",
       " 'oacb',\n",
       " 'boundary',\n",
       " 'pf_1',\n",
       " 'bz_1',\n",
       " 'participants',\n",
       " 'computer',\n",
       " 'rail',\n",
       " 'le3x',\n",
       " 'flow',\n",
       " 'mrt',\n",
       " 'parcels',\n",
       " 'arguments',\n",
       " 'industry',\n",
       " 'stage',\n",
       " 'named',\n",
       " 'appu',\n",
       " 'p_0',\n",
       " '6at',\n",
       " 'bb',\n",
       " '1_n',\n",
       " 'counts',\n",
       " 'manned',\n",
       " 'chandigarh',\n",
       " 'expanses',\n",
       " 'posted',\n",
       " 'entire',\n",
       " 'fish',\n",
       " 'coaxal',\n",
       " 'oa_i',\n",
       " 'aog',\n",
       " 'inclination',\n",
       " 'alloy',\n",
       " 'log_75',\n",
       " 'medicine',\n",
       " 'collections',\n",
       " 'neglecting',\n",
       " '8f',\n",
       " 'midterm',\n",
       " 'design',\n",
       " 'met',\n",
       " '1y',\n",
       " 'pmn',\n",
       " 'aod',\n",
       " 'click',\n",
       " 'cause',\n",
       " 'able',\n",
       " 'gifts',\n",
       " '_cf',\n",
       " '9kx',\n",
       " 'output',\n",
       " 'december',\n",
       " 'h_7',\n",
       " 'ignoring',\n",
       " 'np_',\n",
       " 'guessing',\n",
       " 'cosğ‘ğ‘¥',\n",
       " 'geq2',\n",
       " 'pss',\n",
       " 'equallydistribute',\n",
       " 'expresion',\n",
       " 'enclose',\n",
       " 'intoidentify',\n",
       " 'idempotent',\n",
       " 'ion',\n",
       " '_e',\n",
       " 'obtaining',\n",
       " 'parablas',\n",
       " 'kota',\n",
       " 'depicts',\n",
       " 'i3',\n",
       " '5e',\n",
       " 'coloured',\n",
       " '7c_3',\n",
       " '6000',\n",
       " 'file',\n",
       " 'bonded',\n",
       " 'int_3',\n",
       " 'differentiations',\n",
       " 'p_1q_0',\n",
       " 'h_3',\n",
       " '19x',\n",
       " 'chairman',\n",
       " 'is4if',\n",
       " '3333',\n",
       " 'logics',\n",
       " 'cos3c',\n",
       " 'cmsnumber',\n",
       " 'pays',\n",
       " 'labeled',\n",
       " '7_',\n",
       " 'husky',\n",
       " 'sqrt6',\n",
       " 'defining',\n",
       " 'circumscribed',\n",
       " 'nc_6',\n",
       " 'contigency',\n",
       " '5th',\n",
       " 'm_1m_2',\n",
       " 'continue',\n",
       " 'hastwo',\n",
       " 'cdot6',\n",
       " '7ğœ‹',\n",
       " '9_0f',\n",
       " 'stable',\n",
       " 'converted',\n",
       " 'log_210',\n",
       " 'log_816',\n",
       " 'debate',\n",
       " 'bat',\n",
       " 'n_k',\n",
       " 'completes',\n",
       " 'poq',\n",
       " 'kr',\n",
       " 'delta_1',\n",
       " 'emanating',\n",
       " 'deposited',\n",
       " 'minimal',\n",
       " 'n_1a_n',\n",
       " '7c_2',\n",
       " 'happen',\n",
       " 'nilpotent',\n",
       " 'cos23',\n",
       " '_x2',\n",
       " 'consistency',\n",
       " 'illuminated',\n",
       " 'octant',\n",
       " 'doubles',\n",
       " 'cdot8',\n",
       " 'constrained',\n",
       " '64k',\n",
       " 'oe',\n",
       " 'rahul',\n",
       " 'parallelepiped',\n",
       " 'belowthe',\n",
       " 'log_x8',\n",
       " 'managed',\n",
       " 'bolts',\n",
       " 'attaining',\n",
       " 'pattern',\n",
       " 'parallelogrm',\n",
       " 'pointing',\n",
       " 'mc_m',\n",
       " 'haryana',\n",
       " 'inner',\n",
       " 'lineif',\n",
       " 'a_1c_2',\n",
       " 'blade',\n",
       " 'deck',\n",
       " 'factional',\n",
       " '6c',\n",
       " 'baseline',\n",
       " '654',\n",
       " 'd_j',\n",
       " '__',\n",
       " 'cotc',\n",
       " 'cos2t',\n",
       " 'notes',\n",
       " 'bz_2',\n",
       " 'licences',\n",
       " 'pieces',\n",
       " 'chair',\n",
       " '1958',\n",
       " 'stationery',\n",
       " 'consumers',\n",
       " 'dac',\n",
       " 'checking',\n",
       " '737',\n",
       " 'consulting',\n",
       " 'd_',\n",
       " '7c_3x',\n",
       " 'ln3',\n",
       " 'mth',\n",
       " '9f',\n",
       " 'lowest',\n",
       " 'amout',\n",
       " 'abscissas',\n",
       " 'passenger',\n",
       " 'dg',\n",
       " 'liked',\n",
       " '7c_1',\n",
       " 'chocolate',\n",
       " 'log_7',\n",
       " '720',\n",
       " 'flower',\n",
       " 'pug',\n",
       " 'cosa',\n",
       " 'enlarge',\n",
       " 'mouth',\n",
       " 'extends',\n",
       " 'bulbs',\n",
       " 'logğ‘',\n",
       " 'freely',\n",
       " 'politicians',\n",
       " 'fingers',\n",
       " 'frac1t',\n",
       " 'pentagon',\n",
       " 'halting',\n",
       " 'directionwe',\n",
       " 'a_mx',\n",
       " 'applies',\n",
       " 'november',\n",
       " 'cosğœƒ',\n",
       " '6ğ‘',\n",
       " 'mediterranean',\n",
       " 'frac1z',\n",
       " 'bike',\n",
       " 'jerry',\n",
       " 'cota',\n",
       " 'formulated',\n",
       " '6ix',\n",
       " 'int3',\n",
       " 'gcd',\n",
       " 'antilog',\n",
       " 'factoring',\n",
       " 'combinatorial',\n",
       " 'january',\n",
       " 'directly',\n",
       " 'across',\n",
       " 'coated',\n",
       " 'conducted',\n",
       " '315',\n",
       " 'ni',\n",
       " 'predict',\n",
       " 'dicitionary',\n",
       " 'log_2y',\n",
       " 'nc_j',\n",
       " 'varied',\n",
       " 'oqd',\n",
       " 'spokes',\n",
       " 'np_s',\n",
       " 'nw',\n",
       " 'implicity',\n",
       " 'np_4',\n",
       " '7a',\n",
       " 'qv',\n",
       " 'commonly',\n",
       " 'isneither',\n",
       " 'akhilesh',\n",
       " 'graphical',\n",
       " 'c_1c_',\n",
       " 'monthiii',\n",
       " '78y',\n",
       " 'int5',\n",
       " 'birthday',\n",
       " 'butterscotch',\n",
       " 'ln25',\n",
       " 'integeriv',\n",
       " 'kxy',\n",
       " '685',\n",
       " 'frac32x',\n",
       " 'literal',\n",
       " 'r_n',\n",
       " 'axisrotation',\n",
       " 'epsilon',\n",
       " 'j1',\n",
       " 'intuition',\n",
       " 'log_41024',\n",
       " 'li9ne',\n",
       " 'doberman',\n",
       " 'bolt',\n",
       " 'jack',\n",
       " 'con',\n",
       " 'nx_i',\n",
       " 'prices',\n",
       " 'etc',\n",
       " 'driving',\n",
       " 'pear',\n",
       " 'chairs',\n",
       " 'band',\n",
       " 'orthonormal',\n",
       " 'pd',\n",
       " 'conical',\n",
       " 'hall',\n",
       " 'weighted',\n",
       " 'ce',\n",
       " 'kc',\n",
       " 'latusrecta',\n",
       " 'plotted',\n",
       " 'female',\n",
       " 'cu',\n",
       " '67',\n",
       " 'cosğ›¼',\n",
       " 'instances',\n",
       " 'exp',\n",
       " 'geq3',\n",
       " '6ğ‘¦',\n",
       " 'followed',\n",
       " 'rain',\n",
       " 'a_12',\n",
       " 'northwards',\n",
       " 'banana',\n",
       " 'lnx',\n",
       " 'interesect',\n",
       " 'neighbours',\n",
       " 'others',\n",
       " 'frac35',\n",
       " 'chihuahua',\n",
       " 'cot135',\n",
       " 'elected',\n",
       " 'brilliant',\n",
       " 'iistraight',\n",
       " 'equationi',\n",
       " 'march',\n",
       " 'evenstatement',\n",
       " 'fat',\n",
       " 'grass',\n",
       " 'bj',\n",
       " 'brakes',\n",
       " 'int2sec',\n",
       " 'contacts',\n",
       " 'b_r',\n",
       " 'dropped',\n",
       " 'ot',\n",
       " 'a_0x',\n",
       " 'completely',\n",
       " 'endanoele',\n",
       " 'cv_x',\n",
       " 'pm4',\n",
       " '1986',\n",
       " 'external',\n",
       " '9192',\n",
       " 'exams',\n",
       " 'wave',\n",
       " '8xy',\n",
       " '1the',\n",
       " 'probablity',\n",
       " 'log_56',\n",
       " 'economical',\n",
       " 'integrate',\n",
       " 'asks',\n",
       " 'ea',\n",
       " 'millioniv',\n",
       " '_m',\n",
       " 'rakshit',\n",
       " 'railway',\n",
       " 'liters',\n",
       " 'finitely',\n",
       " '1n',\n",
       " 'decompose',\n",
       " 'a_0a_4',\n",
       " 'log_ac',\n",
       " 'positivie',\n",
       " 'print',\n",
       " 'houses',\n",
       " 'close',\n",
       " 'numberzeroan',\n",
       " 'expands',\n",
       " 'observes',\n",
       " 'passengers',\n",
       " 'dataheight',\n",
       " 'abx',\n",
       " 'predicted',\n",
       " 'layers',\n",
       " 'l_0',\n",
       " '90000',\n",
       " 'often',\n",
       " 'comprising',\n",
       " 'commute',\n",
       " 'graduate',\n",
       " 'detector',\n",
       " 'ducks',\n",
       " 'firm',\n",
       " 'le8x',\n",
       " '334',\n",
       " 'nr',\n",
       " 'cos179',\n",
       " 'classto',\n",
       " 'cost',\n",
       " 'iifor',\n",
       " 'necklaces',\n",
       " 'pl',\n",
       " 'menu',\n",
       " 'discovered',\n",
       " 'goa',\n",
       " 'various',\n",
       " 'maximums',\n",
       " 'cot150',\n",
       " 'a_2c_1',\n",
       " 'bomb',\n",
       " '6bx',\n",
       " 'pay',\n",
       " 'iw',\n",
       " 'fails',\n",
       " 'd_3',\n",
       " 'exam',\n",
       " 'coincident',\n",
       " 'll',\n",
       " 'oncircleif',\n",
       " 'log_24',\n",
       " 'ne4',\n",
       " 'april',\n",
       " 'employees',\n",
       " 'inex',\n",
       " 'library',\n",
       " '_i',\n",
       " '5c_3x',\n",
       " 'believe',\n",
       " 'pba',\n",
       " 'log_ğ‘',\n",
       " 'cos7',\n",
       " 'is18the',\n",
       " 'kz',\n",
       " 'candidates',\n",
       " 'coterminous',\n",
       " 'feeling',\n",
       " 'log_aa',\n",
       " 'iiplane',\n",
       " 'alpha_k',\n",
       " 'pp',\n",
       " 'onhyperbola',\n",
       " '1_0xe',\n",
       " 'functioniiiiiiv',\n",
       " '64z_3z_1',\n",
       " '94',\n",
       " 'log_216',\n",
       " 'progress',\n",
       " 'germany',\n",
       " 'bought',\n",
       " 'piles',\n",
       " 'august',\n",
       " 'july',\n",
       " 'abut',\n",
       " 'eyes',\n",
       " 'kğ‘¦',\n",
       " 'laid',\n",
       " 'formation',\n",
       " 'mrn',\n",
       " '7dx',\n",
       " 'experiments',\n",
       " 'loan',\n",
       " 'nearer',\n",
       " 'discarded',\n",
       " 'prq',\n",
       " 'frac23a',\n",
       " 'al',\n",
       " 'bn',\n",
       " 'concyclic',\n",
       " '6500',\n",
       " '3195',\n",
       " 'discrete',\n",
       " 'napier',\n",
       " 'spell',\n",
       " 'mass',\n",
       " 'log_e16',\n",
       " 'indirect',\n",
       " 'night',\n",
       " '____0',\n",
       " '5m',\n",
       " 'evening',\n",
       " 'bags',\n",
       " 'newspapers',\n",
       " 'statisfies',\n",
       " 'buys',\n",
       " 'b2',\n",
       " 'boat',\n",
       " 'parcel',\n",
       " 'w_1',\n",
       " '916238457',\n",
       " 'denomination',\n",
       " 'partner',\n",
       " 'exterior',\n",
       " '77',\n",
       " 'vy',\n",
       " 'description',\n",
       " 'infty_',\n",
       " 'plotting',\n",
       " '8iz',\n",
       " 'accuracy',\n",
       " 'labrador',\n",
       " 'l_k',\n",
       " 'mantissa',\n",
       " 'a_m',\n",
       " '18ğ‘¦',\n",
       " '71',\n",
       " 'mechanical',\n",
       " '_xf',\n",
       " '337',\n",
       " 'offer',\n",
       " 'endlessly',\n",
       " 'cos3b',\n",
       " 'captain',\n",
       " 'book',\n",
       " 'october',\n",
       " 'are1points',\n",
       " 'assistant',\n",
       " 'melts',\n",
       " 'centoid',\n",
       " 'nr_i',\n",
       " 'cpb',\n",
       " 'poodle',\n",
       " 'individually',\n",
       " 'forecasts',\n",
       " 'p2',\n",
       " 'pile',\n",
       " 'producing',\n",
       " 'dentoes',\n",
       " 'grows',\n",
       " 'erases',\n",
       " 'frac15',\n",
       " 'log_9x',\n",
       " '338',\n",
       " 'originating',\n",
       " 'ans',\n",
       " 'stationary',\n",
       " 'station',\n",
       " 'gap',\n",
       " 'carromboard',\n",
       " 'ef',\n",
       " 'variety',\n",
       " 'dayoption',\n",
       " 'equivalently',\n",
       " 'frac72',\n",
       " 'flows',\n",
       " 'near',\n",
       " 'n2',\n",
       " 'creams',\n",
       " '2ğ‘›',\n",
       " 'material',\n",
       " 'pick',\n",
       " 'f_0',\n",
       " 'odc',\n",
       " 'gab',\n",
       " 'canal',\n",
       " 'nn',\n",
       " 'fan',\n",
       " '810',\n",
       " 'owner',\n",
       " 'chocolates',\n",
       " 'a_2y',\n",
       " '7_4f',\n",
       " 'dash',\n",
       " 'abcde',\n",
       " 'neq0',\n",
       " 'cos2a',\n",
       " 'geometrically',\n",
       " 'bpc',\n",
       " 'covering',\n",
       " 'lawii',\n",
       " 'expensive',\n",
       " 'moivre',\n",
       " 'dairy',\n",
       " 'f_1mn',\n",
       " 'flaws',\n",
       " 'methodheight',\n",
       " 'le36',\n",
       " 'disjointregion',\n",
       " 'hindustan',\n",
       " 'peer',\n",
       " 'successful',\n",
       " '8_',\n",
       " 'oscillation',\n",
       " 'exercise',\n",
       " 'asian',\n",
       " 'firms',\n",
       " 'fatal',\n",
       " 'log_ab',\n",
       " 'frac34',\n",
       " 'r_p',\n",
       " 'doesn',\n",
       " 'committees',\n",
       " '777',\n",
       " 'log_78',\n",
       " 'deal',\n",
       " '7z',\n",
       " 'ey',\n",
       " 'pi3',\n",
       " 'eastwards',\n",
       " 'ge2y',\n",
       " 'pc_2',\n",
       " 'outer',\n",
       " 'p3',\n",
       " 'propositions',\n",
       " 'daily',\n",
       " 'ln5x',\n",
       " 'flag',\n",
       " 'p_2q_1',\n",
       " 'front',\n",
       " 'considering',\n",
       " 'beams',\n",
       " 'planar',\n",
       " 'garden',\n",
       " 'playstation',\n",
       " 'immediately',\n",
       " 'bot',\n",
       " 'iy_0',\n",
       " 'cv_y',\n",
       " 'ge26',\n",
       " 'loci_mystery',\n",
       " 'include',\n",
       " 'ministers',\n",
       " '7creating',\n",
       " '800',\n",
       " 'mistress',\n",
       " 'intervention',\n",
       " 'm0',\n",
       " 'log_22',\n",
       " 'inersection',\n",
       " 'az_2',\n",
       " 'chemistry',\n",
       " 'numberii',\n",
       " 'factorial',\n",
       " 'nz',\n",
       " 'mf_1nf_2',\n",
       " 'df_1',\n",
       " 'juniors',\n",
       " '8ğ‘¥',\n",
       " 'qz',\n",
       " 'characteristic',\n",
       " 'ptq',\n",
       " 'bk',\n",
       " 'litres',\n",
       " 'earth',\n",
       " 'otherwise',\n",
       " 'pillar',\n",
       " 'increment',\n",
       " 'concur',\n",
       " 'perpendicularly',\n",
       " 'subtract',\n",
       " 'rajdhani',\n",
       " 'ddot',\n",
       " 'forward',\n",
       " 'cutting',\n",
       " 'endeanoel',\n",
       " 'avarage',\n",
       " 'me',\n",
       " 'conormal',\n",
       " 'exchanged',\n",
       " '8z',\n",
       " 'aboc',\n",
       " 'country',\n",
       " 'beings',\n",
       " 'omn',\n",
       " '5kx',\n",
       " 'commences',\n",
       " 'stages',\n",
       " '9z_1z_3z_4',\n",
       " '6s_',\n",
       " 'application',\n",
       " 'pears',\n",
       " 'produces',\n",
       " 'allowable',\n",
       " 'assigned',\n",
       " 'hğ‘¥',\n",
       " 'pint',\n",
       " 'mc_1',\n",
       " 'c_j',\n",
       " 'parabolaif',\n",
       " 'lose',\n",
       " 'alongside',\n",
       " 'q_2',\n",
       " 'heightweightmean',\n",
       " 'posed',\n",
       " 'partly',\n",
       " 'cs',\n",
       " 'elimination',\n",
       " 'int7e',\n",
       " '8ğ‘¦',\n",
       " 'averaged',\n",
       " 'eb',\n",
       " 'manners',\n",
       " 'log_yx',\n",
       " 'followinglist',\n",
       " 'cubical',\n",
       " 'human',\n",
       " 'lawiii',\n",
       " '9ax',\n",
       " 'cotb',\n",
       " 'momentarily',\n",
       " 'du',\n",
       " 'miles',\n",
       " 'participant',\n",
       " '9c_3',\n",
       " '715',\n",
       " 'kink',\n",
       " '5d',\n",
       " '6c_2x',\n",
       " 'c_0c_r',\n",
       " 'batman',\n",
       " 'lives',\n",
       " 'portioned',\n",
       " 'int4',\n",
       " 'chapter',\n",
       " 'indianoil',\n",
       " 'complementary',\n",
       " 'c_i',\n",
       " 'ak',\n",
       " 'aeroplanes',\n",
       " 'pth',\n",
       " 'w_2',\n",
       " '8th',\n",
       " '7lnx',\n",
       " 'frac1e',\n",
       " 'eta',\n",
       " 'fin',\n",
       " 'consist',\n",
       " 'independently',\n",
       " 'cos5x',\n",
       " 'pm3',\n",
       " 'wage',\n",
       " '_r',\n",
       " 'currency',\n",
       " 'frac1m',\n",
       " 'attempting',\n",
       " 'edx',\n",
       " 'hydrochloric',\n",
       " 'p_r',\n",
       " 'directories',\n",
       " '9999',\n",
       " 'frac5',\n",
       " '5f',\n",
       " 'parbola',\n",
       " 'kohli',\n",
       " 'nc_5',\n",
       " 'counters',\n",
       " '19202122',\n",
       " 'pnumber',\n",
       " 'market',\n",
       " 'le15',\n",
       " 'mq',\n",
       " 'juice',\n",
       " '1e',\n",
       " 'rank',\n",
       " 'objectsstatement',\n",
       " 'alwaysiii',\n",
       " 'kf',\n",
       " 'equaliv',\n",
       " 'factorisation',\n",
       " 'dat',\n",
       " 'ağ‘¥',\n",
       " 'earners',\n",
       " 'decide',\n",
       " 'daynumber',\n",
       " '74x',\n",
       " 'descending',\n",
       " 'gravitational',\n",
       " 'cirumscribes',\n",
       " 'prod_',\n",
       " '5ğ‘¥',\n",
       " 'container',\n",
       " 'moreover',\n",
       " 'hot',\n",
       " 'a_4h_7',\n",
       " 'laps',\n",
       " 'language',\n",
       " 'vsdjnv',\n",
       " '7_2f',\n",
       " 'log_n8',\n",
       " 'aces',\n",
       " 'integera',\n",
       " '840',\n",
       " 'aj',\n",
       " 'bicycle',\n",
       " 'entity',\n",
       " 'draws',\n",
       " 'maybe',\n",
       " 'n_0f',\n",
       " 'pendulum',\n",
       " 'powerboats',\n",
       " '76',\n",
       " 'int_k',\n",
       " 'frac1n',\n",
       " 'qu',\n",
       " 'mqr',\n",
       " 'malayalam',\n",
       " 'suffering',\n",
       " 'kunal',\n",
       " 'fc',\n",
       " 'geq2x',\n",
       " 'characteristics',\n",
       " '6ğ‘¥',\n",
       " '6n',\n",
       " 'males',\n",
       " 'log_34',\n",
       " 'learn',\n",
       " 'd_k',\n",
       " 'moderately',\n",
       " 'additional',\n",
       " 'count',\n",
       " 'obd',\n",
       " 'plate',\n",
       " 'pap',\n",
       " 'alive',\n",
       " 'escape',\n",
       " 'journey',\n",
       " 'jill',\n",
       " 'installment',\n",
       " 'lettered',\n",
       " 'isf',\n",
       " 'concylic',\n",
       " 'chi',\n",
       " 'deliveries',\n",
       " 'husband',\n",
       " 'grand',\n",
       " '19let',\n",
       " 'expansions',\n",
       " 'wants',\n",
       " '7ğ‘š',\n",
       " 'mins',\n",
       " 'came',\n",
       " 'heights',\n",
       " 'log_cb',\n",
       " 'a4',\n",
       " 'apply',\n",
       " 'annual',\n",
       " 'imposed',\n",
       " 'involving',\n",
       " 'logğ‘',\n",
       " '900',\n",
       " 'nk',\n",
       " 'qd',\n",
       " 'engineering',\n",
       " 'arround',\n",
       " 'cos3a',\n",
       " 'geq1',\n",
       " 'brand',\n",
       " 'fast',\n",
       " 'nearby',\n",
       " 'ixx',\n",
       " '723',\n",
       " 'special',\n",
       " 'c_2c_',\n",
       " 'international',\n",
       " 'gx',\n",
       " '333',\n",
       " 'alpha2',\n",
       " 'log_2n',\n",
       " 'mouse',\n",
       " 'daughters',\n",
       " '192x',\n",
       " 'farther',\n",
       " 'fuel',\n",
       " 'derive',\n",
       " 'omitted',\n",
       " 'oac',\n",
       " 'ace',\n",
       " '2008',\n",
       " 'lost',\n",
       " 'properly',\n",
       " 'log_42',\n",
       " 'frac1y',\n",
       " 'lamp',\n",
       " 'fnd',\n",
       " 'manchester',\n",
       " 'a_0a_2',\n",
       " 'input',\n",
       " 'canvas',\n",
       " 'distibuted',\n",
       " 'deleted',\n",
       " 'kg',\n",
       " 'jaya',\n",
       " 'pv',\n",
       " 'deposits',\n",
       " 'occuring',\n",
       " 'listed',\n",
       " 'approx',\n",
       " 'pw',\n",
       " 'emitted',\n",
       " 'kc_r',\n",
       " 'ci',\n",
       " 'hunter',\n",
       " 'knows',\n",
       " 'color',\n",
       " 'metal',\n",
       " 'diffrential',\n",
       " 'fencing',\n",
       " 'papers',\n",
       " 'passport',\n",
       " 'hence',\n",
       " 'coming',\n",
       " 'funciotn',\n",
       " 'failed',\n",
       " 'bed',\n",
       " '992',\n",
       " 'opqrs',\n",
       " 'differences',\n",
       " 'le7',\n",
       " 'eventswhich',\n",
       " 'complimentary',\n",
       " 'confirms',\n",
       " 'eccentriciyt',\n",
       " 'cj',\n",
       " '9k',\n",
       " 'additioni',\n",
       " 'p_nq_',\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "        vocabulary=None)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.4806590257879656\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.GaussianNB(), xtrain_count.todense(), train_y, xvalid_count.todense())\n",
    "print(\"NB, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
